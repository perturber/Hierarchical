{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0253967-6859-4be8-ad31-20391fb551ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startup\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "try:\n",
    "    import cupy as cp\n",
    "    use_gpu = True\n",
    "except:\n",
    "    use_gpu = False\n",
    "import pickle\n",
    "import time\n",
    "import h5py\n",
    "\n",
    "from stableemrifisher.fisher import StableEMRIFisher\n",
    "from stableemrifisher.utils import inner_product, generate_PSD, padding\n",
    "\n",
    "from few.utils.utility import get_p_at_t\n",
    "from few.trajectory.inspiral import EMRIInspiral\n",
    "from few.trajectory.ode import KerrEccEqFlux\n",
    "\n",
    "from few.waveform import GenerateEMRIWaveform\n",
    "from few.summation.aakwave import AAKSummation\n",
    "from few.utils.constants import YRSID_SI\n",
    "from few.utils.constants import SPEED_OF_LIGHT as C_SI\n",
    "from few.utils.geodesic import ELQ_to_pex, get_kerr_geo_constants_of_motion\n",
    "\n",
    "from fastlisaresponse import ResponseWrapper  # Response function \n",
    "from lisatools.detector import ESAOrbits #ESAOrbits correspond to esa-trailing-orbits.h5\n",
    "\n",
    "from scipy.integrate import quad, nquad\n",
    "from scipy.interpolate import RegularGridInterpolator, CubicSpline\n",
    "from scipy.stats import uniform\n",
    "from scipy.special import factorial\n",
    "from scipy.optimize import brentq, root\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "import warnings\n",
    "\n",
    "from hierarchical.FisherValidation import FisherValidation\n",
    "from hierarchical.utility import H, integrand_dc, dc, getdistGpc, dlminusdistz, getz, Jacobian, check_prior\n",
    "from hierarchical.JointWave import JointKerrWaveform, JointRelKerrEccFlux\n",
    "\n",
    "\n",
    "#lots of supporting utility functions\n",
    "\n",
    "if not use_gpu:\n",
    "    cfg_set = few.get_config_setter(reset=True)\n",
    "    cfg_set.enable_backends(\"cpu\")\n",
    "    cfg_set.set_log_level(\"info\")\n",
    "else:\n",
    "    pass #let the backend decide for itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0150c787-d640-48dc-a892-f0bf6522b3ad",
   "metadata": {},
   "source": [
    "# Lots of Supporting Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02709fa6-870b-41bf-a211-bfe38f19e05f",
   "metadata": {},
   "source": [
    "#### source parameter prior pdfs in all three hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2f242c3-0d97-41a6-9da7-8b6e15fa90c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#supporting functions for prior_vac\n",
    "def Mz_func(M, z, K, alpha, beta, H0, Omega_m0,Omega_Lambda0, Mstar):\n",
    "    return K*(M/Mstar)**alpha*(1+z)**beta*4*np.pi*dc(z,H0,Omega_m0,Omega_Lambda0)**2\n",
    "\n",
    "def prior_vac(M, z, K, alpha, beta, H0, Omega_m0,Omega_Lambda0, Mstar):\n",
    "    \"\"\"\n",
    "    given the vacuum hyperparams [K,alpha,beta],\n",
    "    calculate the UNNORMALIZED probability distribution function of \n",
    "    obtaining the source params [M,z]\n",
    "    \"\"\"\n",
    "    \n",
    "    return Mz_func(M,z,K,alpha,beta,H0, Omega_m0,Omega_Lambda0, Mstar)\n",
    "\n",
    "def prior_loc(vec_l, f, mu_l, sigma_l):\n",
    "    \"\"\"\n",
    "    given the local effect hyperparams [f,[mu_Al, mu_nl],[sigma_Al,sigma_nl]],\n",
    "    calculate the probability distribution function of \n",
    "    obtaining the source params vec_l = [A_l,n_l]\n",
    "    \"\"\"\n",
    "\n",
    "    vec_l = np.array(vec_l)\n",
    "    mu_l = np.array(mu_l)\n",
    "    sigma_l = np.array(sigma_l)\n",
    "    \n",
    "    Gamma_l = np.diag(1/sigma_l**2)\n",
    "\n",
    "    return f*np.linalg.det(Gamma_l)**(1/2)/(2*np.pi)*np.exp(-0.5*(vec_l-mu_l)@Gamma_l@(vec_l-mu_l))\n",
    "\n",
    "def prior_glob(A_g, Gdot, atol=1e-14):\n",
    "    \"\"\"\n",
    "    given the global effect hyperparam [Gdot],\n",
    "    calculate the probability distribution function of \n",
    "    obtaining the source params vec_g = [A_g]\n",
    "    \"\"\"\n",
    "    if np.isclose(A_g,Gdot,rtol=atol, atol=atol):\n",
    "        return 1.\n",
    "    else:\n",
    "        return 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d1af7b-3e8b-44b3-b750-9584881b73f7",
   "metadata": {},
   "source": [
    "#### generating source parameter samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a56b3722-11cc-46f4-9641-4342109c51d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_z_samples(N,M_range,z_range,lambda_v,grid_size,H0,Omega_m0,Omega_Lambda0,Mstar,seed):\n",
    "    \"\"\" function to generate N samples of the local effect parameters M, z\n",
    "    from M in Mrange, z in zrange, given hyperparameters lambda_v and a grid of size grid_size\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "\n",
    "    K_truth, alpha_truth, beta_truth = lambda_v\n",
    "\n",
    "    M_grid = uniform.rvs(loc=M_range[0],scale=M_range[1]-M_range[0],size=grid_size) #generating samples first from a uniform grid\n",
    "    z_grid = uniform.rvs(loc=z_range[0],scale=z_range[1]-z_range[0],size=grid_size)\n",
    "\n",
    "    prior_Mz = []\n",
    "    for i in range(grid_size):\n",
    "        prior_Mz.append(prior_vac(M_grid[i],z_grid[i],K_truth,alpha_truth,beta_truth,H0, Omega_m0,Omega_Lambda0,Mstar))\n",
    "    \n",
    "    prior_Mz = np.array(prior_Mz)/np.sum(np.array(prior_Mz)) #normalizing\n",
    "    \n",
    "    #choosing N sources based on the probability distribution\n",
    "    indices = range(grid_size)\n",
    "    chosen = np.random.choice(indices,size=N,p=prior_Mz)\n",
    "    M_samples = M_grid[chosen]\n",
    "    z_samples = z_grid[chosen]    \n",
    "\n",
    "    return M_samples, z_samples\n",
    "\n",
    "def A_n_samples(N,lambda_l,seed):\n",
    "    \"\"\" function to generate N samples of the local effect parameters A_l, n_l\n",
    "    from A_l in Al_range, n_l in nl_range, given hyperparameters lambda_l and a grid of size grid_size\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    f, mu_l, sigma_l = lambda_l\n",
    "\n",
    "    if f == 0.0:\n",
    "        Al_samples = np.zeros(N)\n",
    "        nl_samples = np.zeros(N)\n",
    "        \n",
    "    else:\n",
    "        cov = [[sigma_l[0]**2, 0],[0,sigma_l[1]**2]]\n",
    "        Al_samples, nl_samples = np.random.multivariate_normal(mean=mu_l,cov=cov,size=int(f*N)).T\n",
    "        Al_samples = np.concatenate((Al_samples,np.zeros(N-int(f*N))))\n",
    "        nl_samples = np.concatenate((nl_samples,np.zeros(N-int(f*N))))\n",
    "        \n",
    "    return Al_samples, nl_samples\n",
    "\n",
    "def Ag_samples(N,lambda_g):\n",
    "    \"\"\" function to generate N samples of the global effect parameter Ag\n",
    "    given hyperparameter lambda_g\n",
    "    \"\"\"\n",
    "    return np.ones(N)*lambda_g #just a Dirac Delta\n",
    "\n",
    "def other_param_samples(N,M_samples,Tplunge_range,seed):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    Trange = Tplunge_range #time-to-plunge (from initiation) of the EMRI population. This is an important (but unfortunately FREE) parameter to control the number of observed EMRIs.\n",
    "    \n",
    "    Tstar = uniform.rvs(loc=Trange[0],scale=Trange[1]-Trange[0],size=N) #randomly choosing time of plunge for the Nth EMRI in the population\n",
    "    \n",
    "    log10qrange = [-5.5,-4.5] #range of log10 mass ratios\n",
    "    qrange = 10**uniform.rvs(loc=log10qrange[0],scale=log10qrange[1]-log10qrange[0],size=N) #samples of mass ratios\n",
    "    mustar = M_samples*qrange #samples of CO masses\n",
    "    \n",
    "    arange = [0.5,0.99] #MBH spin\n",
    "    astar = uniform.rvs(loc=arange[0],scale=arange[1]-arange[0],size=N)\n",
    "    \n",
    "    qSrange = [0.0,np.pi] #polar sky location\n",
    "    qSstar = uniform.rvs(loc=qSrange[0],scale=qSrange[1]-qSrange[0],size=N)\n",
    "    qKstar = uniform.rvs(loc=qSrange[0],scale=qSrange[1]-qSrange[0],size=N) #polar spin orientation\n",
    "    \n",
    "    phiSrange = [0.0,2*np.pi] #azimuthal sky location\n",
    "    phiSstar = uniform.rvs(loc=phiSrange[0],scale=phiSrange[1]-phiSrange[0],size=N)\n",
    "    phiKstar = uniform.rvs(loc=phiSrange[0],scale=phiSrange[1]-phiSrange[0],size=N) #azimuthal spin orientation\n",
    "    Phi0star = uniform.rvs(loc=phiSrange[0],scale=phiSrange[1]-phiSrange[0],size=N) #circ-ecc init EMRI phase\n",
    "    \n",
    "    return mustar, astar, qSstar, qKstar, phiSstar, phiKstar, Phi0star, Tstar\n",
    "\n",
    "def p0_samples_func(N,Msamps,musamps,asamps,Alsamps,nlsamps,Agsamps,Tsamps,seed,filename):\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    traj_xy = EMRIInspiral(func=JointRelKerrEccFlux)\n",
    "    \n",
    "    p0samps = []\n",
    "    \n",
    "    for i in tqdm(range(N)):\n",
    "        #print(Tsamps[i],Msamps[i],musamps[i],asamps[i],Alsamps[i],nlsamps[i],Agsamps[i])\n",
    "        \n",
    "        p_plunge = get_p_at_t(traj_xy,\n",
    "                              Tsamps[i],\n",
    "                              [Msamps[i],\n",
    "                               musamps[i],\n",
    "                               asamps[i],\n",
    "                               0.0, #e0\n",
    "                               1.0, #Y0\n",
    "                               Alsamps[i],\n",
    "                               nlsamps[i],\n",
    "                               Agsamps[i],\n",
    "                               4.0 #ng\n",
    "                              ],\n",
    "                              )\n",
    "        \n",
    "        p0samps.append(p_plunge + 1.0)\n",
    "\n",
    "    np.save(f\"{filename}/p0samps\",p0samps)\n",
    "    \n",
    "    return np.array(p0samps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5862740-a3d8-4ae2-aa65-9fee38bca643",
   "metadata": {},
   "source": [
    "#### Bias calculation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d67a3192-610e-4288-86df-de1fdb9f87d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias(psi_signal,phi_signal,multiplicative_factor):\n",
    "    \"\"\" \n",
    "    Given a true signal with decomposed param set (psi, phi) and the multiplicative factor,\n",
    "    calculate the biased param vector psi_bias.\n",
    "    (See Eq. 11 in https://arxiv.org/abs/2312.13028)\n",
    "    \"\"\"\n",
    "    # d: number of measured source params\n",
    "    # Nphi: number of unmeasured params\n",
    "    # Npsi: number of measured params\n",
    "\n",
    "    phi_signal = np.atleast_1d(phi_signal)\n",
    "    \n",
    "    delta_phi = phi_signal - np.zeros(len(phi_signal)) #1D array - 1D array = 1D array of length Nphi\n",
    "        \n",
    "    #print(delta_phi)\n",
    "    \n",
    "    delta_psi = multiplicative_factor@delta_phi # Npsi x Nphi array times Nphi 1D array: 1D array of length Npsi\n",
    "    \n",
    "    #print(psi_ML)\n",
    "\n",
    "    return psi_signal + delta_psi # Npsi 1D array + Npsi 1D array = Npsi 1D array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010d6900-db97-4bbf-bb93-f85c87709da6",
   "metadata": {},
   "source": [
    "#### Source integral prior_vac derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5634cbc2-67e7-4648-bf65-651844e27318",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## supporting functions ###########################################\n",
    "\n",
    "def Ddc(z,H0,Omega_m0,Omega_Lambda0):\n",
    "    \"\"\"calculate the first derivative of comoving distance with respect to z\"\"\"\n",
    "    return integrand_dc(z,H0,Omega_m0,Omega_Lambda0)\n",
    "\n",
    "def DDdc(z,H0,Om,Ol):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes the expression:\n",
    "    \n",
    "    -((3 * c * H0 * Om^(2/3) * (1 + z) * (Om * (1 + z)^3)^(3/2) *\n",
    "    (Ol^(4/3) * Om^(1/3) * (1 + z) +\n",
    "     3 * H0^(2/3) * Ol^(2/3) * Om^(2/3) * (1 + z)^2 +\n",
    "     H0^(4/3) * Om * (1 + z)^3 -\n",
    "     2 * H0^(1/3) * Ol * sqrt(Om * (1 + z)^3) -\n",
    "     2 * H0 * Ol^(1/3) * Om^(1/3) * (1 + z) * sqrt(Om * (1 + z)^3)))\n",
    "     / (2 * (Ol^(1/3) * Om^(1/3) * (1 + z) + H0^(1/3) * sqrt(Om * (1 + z)^3))^2 *\n",
    "        (Ol^(2/3) * Om^(1/3) * (1 + z) +\n",
    "         H0^(2/3) * Om^(2/3) * (1 + z)^2 -\n",
    "         H0^(1/3) * Ol^(1/3) * sqrt(Om * (1 + z)^3))^4))\n",
    "\n",
    "    Parameters:\n",
    "        c, H0, Om, Ol, z : float\n",
    "            Constants and variable in the expression\n",
    "    \"\"\"\n",
    "    \n",
    "    # Numerator terms\n",
    "    term1 = Ol ** (4/3) * Om ** (1/3) * (1 + z)\n",
    "    term2 = 3 * H0 ** (2/3) * Ol ** (2/3) * Om ** (2/3) * (1 + z) ** 2\n",
    "    term3 = H0 ** (4/3) * Om * (1 + z) ** 3\n",
    "    term4 = -2 * H0 ** (1/3) * Ol * np.sqrt(Om * (1 + z) ** 3)\n",
    "    term5 = -2 * H0 * Ol ** (1/3) * Om ** (1/3) * (1 + z) * np.sqrt(Om * (1 + z) ** 3)\n",
    "    \n",
    "    numerator = (-3 * C_SI * H0 * Om ** (2/3) * (1 + z) * (Om * (1 + z) ** 3) ** (3/2) *\n",
    "                 (term1 + term2 + term3 + term4 + term5))\n",
    "\n",
    "    # Denominator terms\n",
    "    denom1 = Ol ** (1/3) * Om ** (1/3) * (1 + z) + H0 ** (1/3) * np.sqrt(Om * (1 + z) ** 3)\n",
    "    denom2 = (Ol ** (2/3) * Om ** (1/3) * (1 + z) +\n",
    "              H0 ** (2/3) * Om ** (2/3) * (1 + z) ** 2 -\n",
    "              H0 ** (1/3) * Ol ** (1/3) * np.sqrt(Om * (1 + z) ** 3))\n",
    "\n",
    "    denominator = 2 * denom1 ** 2 * denom2 ** 4\n",
    "\n",
    "    return numerator / denominator\n",
    "\n",
    "######## pvac derivatives #########################################################\n",
    "def DDM_prior_vac(M, z, K, alpha, beta, H0, Omega_m0,Omega_Lambda0, Mstar):\n",
    "    C = K*(1/Mstar)**alpha*4*np.pi\n",
    "\n",
    "    return C*alpha*(alpha-1)*M**(alpha-2)*(1+z)**beta*dc(z,H0,Omega_m0,Omega_Lambda0)**2\n",
    "\n",
    "def DDz_prior_vac(M, z, K, alpha, beta,H0,Omega_m0,Omega_Lambda0, Mstar):\n",
    "    C = K*(1/Mstar)**alpha*4*np.pi\n",
    "\n",
    "    \"\"\"\n",
    "    Computes the expression given in Mathematica syntax:\n",
    "    \n",
    "    (-1 + beta) * beta * C * M^alpha * (1 + z)^(-2 + beta) * dc[z]^2 \n",
    "    + 4 * beta * C * M^alpha * (1 + z)^(-1 + beta) * dc[z] * Derivative[1][dc][z] \n",
    "    + 2 * C * M^alpha * (1 + z)^beta * Derivative[1][dc][z]^2 \n",
    "    + 2 * C * M^alpha * (1 + z)^beta * dc[z] * (dc''[z])\n",
    "    \n",
    "    Parameters:\n",
    "        beta, C, M, alpha, z : float\n",
    "            Constants and variable in the expression\n",
    "        dc : float\n",
    "            dc[z] (function value at z)\n",
    "        Ddc : float\n",
    "            Derivative of dc with respect to z (dc'[z])\n",
    "        DDdc : float\n",
    "            Second derivative of dc with respect to z (dc''[z])\n",
    "    \"\"\"\n",
    "\n",
    "    term1 = (-1 + beta) * beta * C * M ** alpha * (1 + z) ** (-2 + beta) * dc(z,H0,Omega_m0,Omega_Lambda0)** 2\n",
    "    term2 = 4 * beta * C * M ** alpha * (1 + z) ** (-1 + beta) * dc(z,H0,Omega_m0,Omega_Lambda0)* Ddc(z,H0,Omega_m0,Omega_Lambda0)\n",
    "    term3 = 2 * C * M ** alpha * (1 + z) ** beta * Ddc(z,H0,Omega_m0,Omega_Lambda0) ** 2\n",
    "    term4 = 2 * C * M ** alpha * (1 + z) ** beta * dc(z,H0,Omega_m0,Omega_Lambda0) * DDdc(z,H0,Omega_m0,Omega_Lambda0)\n",
    "    \n",
    "    return term1 + term2 + term3 + term4\n",
    "\n",
    "def DMDz_prior_vac(M, z, K, alpha, beta,H0,Omega_m0,Omega_Lambda0, Mstar):\n",
    "    C = K*(1/Mstar)**alpha*4*np.pi\n",
    "\n",
    "    \"\"\"\n",
    "    Computes the expression:\n",
    "    \n",
    "    alpha * beta * C * M^(-1 + alpha) * (1 + z)^(-1 + beta) * dc[z]^2 \n",
    "    + 2 * alpha * C * M^(-1 + alpha) * (1 + z)^beta * dc[z] * Derivative[1][dc][z]\n",
    "    \n",
    "    Parameters:\n",
    "        alpha, beta, C, M, z : float\n",
    "            Constants and variable in the expression\n",
    "        dc : float\n",
    "            dc[z] (function value at z)\n",
    "        Ddc : float\n",
    "            Derivative of dc with respect to z (dc'[z])\n",
    "    \"\"\"\n",
    "    term1 = alpha * beta * C * M ** (-1 + alpha) * (1 + z) ** (-1 + beta) * dc(z,H0,Omega_m0,Omega_Lambda0) ** 2\n",
    "    term2 = 2 * alpha * C * M ** (-1 + alpha) * (1 + z) ** beta * dc(z,H0,Omega_m0,Omega_Lambda0) * Ddc(z,H0,Omega_m0,Omega_Lambda0)\n",
    "    \n",
    "    return term1 + term2\n",
    "\n",
    "#supporting function for Matrix operations\n",
    "def get_minor(matrix, i, j):\n",
    "    \"\"\"Return the minor of the element at row i and column j.\"\"\"\n",
    "    minor = np.delete(matrix, i, axis=0)  # Remove the i-th row\n",
    "    minor = np.delete(minor, j, axis=1)  # Remove the j-th column\n",
    "    return minor\n",
    "\n",
    "def cofactor_matrix(matrix):\n",
    "    \"\"\"Compute the cofactor matrix of a square matrix.\"\"\"\n",
    "    if matrix.shape[0] != matrix.shape[1]:\n",
    "        raise ValueError(\"Matrix must be square.\")\n",
    "    \n",
    "    n = matrix.shape[0]\n",
    "    cofactor = np.zeros((n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            minor = get_minor(matrix, i, j)\n",
    "            cofactor[i, j] = ((-1) ** (i + j)) * np.linalg.det(minor)\n",
    "    \n",
    "    return cofactor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09972461-0475-48d2-bead-f71055b714aa",
   "metadata": {},
   "source": [
    "#### Individual source integral terms in all three hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e27541a4-b99f-4404-a057-68d3e531a8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Isource_vac(M, z, K, alpha, beta, Fisher, H0,Omega_m0,Omega_Lambda0,Mstar, indices = {'M':0,'z':1}):\n",
    "    \"\"\" Source Integral approximation in the vacuum-GR hypothesis. \n",
    "    M, z are the inferred source parameters. K, alpha, beta are the hyperparameters.\n",
    "    Fisher is the full Fisher matrix in the vac+loc+glob hypothesis at the true parameter point.\n",
    "    indices is a dict of indices of the vacuum parameters [M, z] in the Fisher matrix.\n",
    "    !! Transform Fisher from M, dl to M, z before calling this function !!\n",
    "    \"\"\"\n",
    "        \n",
    "    Fisher_vac_inds = np.ix_(list(indices.values()),list(indices.values()))\n",
    "    Fisher_vac = Fisher[Fisher_vac_inds]\n",
    "    \n",
    "    Fisher_vac_inv = np.linalg.inv(Fisher_vac)\n",
    "\n",
    "    return (prior_vac(M=M, z=z, K=K, alpha=alpha, beta=beta, H0=H0, Omega_m0=Omega_m0, Omega_Lambda0=Omega_Lambda0,Mstar=Mstar) + (1/2*DDM_prior_vac(M=M, z=z, K=K, alpha=alpha, beta=beta, H0=H0, Omega_m0=Omega_m0, Omega_Lambda0=Omega_Lambda0,Mstar=Mstar)*Fisher_vac_inv[indices['M'],indices['M']] +\n",
    "                                                1/2*DDz_prior_vac(M=M, z=z, K=K, alpha=alpha, beta=beta, H0=H0, Omega_m0=Omega_m0, Omega_Lambda0=Omega_Lambda0,Mstar=Mstar)*Fisher_vac_inv[indices['z'],indices['z']] +\n",
    "                                                DMDz_prior_vac(M=M, z=z, K=K, alpha=alpha, beta=beta, H0=H0, Omega_m0=Omega_m0, Omega_Lambda0=Omega_Lambda0,Mstar=Mstar)*Fisher_vac_inv[indices['M'],indices['z']]))\n",
    "\n",
    "\n",
    "def Isource_glob(M, z, Ag, K, alpha, beta, Gdot, Fisher,H0,Omega_m0,Omega_Lambda0, Mstar, indices = {'M':0,'z':1,'Ag':-1}):\n",
    "    \"\"\" Source Integral approximation in the Global effect hypothesis.\n",
    "    M, z, Ag are the inferred source parameters. K, alpha, beta, Gdot are the hyperparameters.\n",
    "    Fisher is the full Fisher matrix in the vac+loc+glob hypothesis at the true parameter point.\n",
    "    indices is a dict of indices of the global parameters [M, z, Ag] in the Fisher matrix.\n",
    "    !! Transform Fisher from M, dl to M, z before calling this function !!\n",
    "    \"\"\"\n",
    "\n",
    "    #getting the Fisher for vac+global effect parameters\n",
    "    dpsi = 3 #len(list(indices.keys())) #number of all parameters in the global effect hypothesis.\n",
    "    \n",
    "    Fisher_psipsi_inds = np.ix_(list(indices.values()),list(indices.values()))\n",
    "    Fisher_psipsi = Fisher[Fisher_psipsi_inds]\n",
    "\n",
    "    #inverse of Fisher_psipsi\n",
    "    Fisher_psipsi_inv = np.linalg.inv(Fisher_psipsi)\n",
    "\n",
    "    #cofactor matrix of Fisher_psipsi\n",
    "    cofactor_psipsi = cofactor_matrix(Fisher_psipsi)\n",
    "    #print('C_MAg: ',cofactor_psipsi[indices['M'],indices['Ag']])\n",
    "    #print('C_zAg: ',cofactor_psipsi[indices['z'],indices['Ag']])\n",
    "    \n",
    "    #getting the Fisher for vac-only parameters\n",
    "    indices_vac = {}\n",
    "    for key in list(indices.keys()):\n",
    "        if key in ['M','z']:\n",
    "            indices_vac[key] = indices[key]\n",
    "\n",
    "    dv = 2 #len(list(indices_vac.keys()))\n",
    "\n",
    "    Fisher_vac_inds = np.ix_(list(indices_vac.values()),list(indices_vac.values()))\n",
    "    Fisher_vac = Fisher[Fisher_vac_inds]\n",
    "\n",
    "    Fisher_vac_inv = np.linalg.inv(Fisher_vac)\n",
    "\n",
    "    #actually calculating the source integral\n",
    "    Constant = ((np.linalg.det(Fisher_psipsi)/np.linalg.det(Fisher_vac))**(1/2))/((2*np.pi)**((dpsi-dv)/2)) #first term\n",
    "\n",
    "    Expterm = np.exp(-1/2 * np.linalg.det(Fisher_psipsi)/np.linalg.det(Fisher_vac) * (Ag-Gdot)**2) #second term\n",
    "\n",
    "    pvacterm = (prior_vac(M=M, z=z, K=K, alpha=alpha, beta=beta, H0=H0, Omega_m0=Omega_m0, Omega_Lambda0=Omega_Lambda0,Mstar=Mstar) + ((1/np.linalg.det(Fisher_vac)**2)*\\\n",
    "                                                                            (1/2*DDM_prior_vac(M=M, z=z, K=K, alpha=alpha, beta=beta, H0=H0, Omega_m0=Omega_m0, Omega_Lambda0=Omega_Lambda0,Mstar=Mstar)*(Fisher_psipsi[0,0]+cofactor_psipsi[indices['M'],indices['Ag']]**2*(Ag-Gdot)**2)\n",
    "                                                                      + 1/2*DDz_prior_vac(M=M, z=z, K=K, alpha=alpha, beta=beta, H0=H0, Omega_m0=Omega_m0, Omega_Lambda0=Omega_Lambda0,Mstar=Mstar)*(Fisher_psipsi[1,1]+cofactor_psipsi[indices['z'],indices['Ag']]**2*(Ag-Gdot)**2)\n",
    "                                                                      + DMDz_prior_vac(M=M, z=z, K=K, alpha=alpha, beta=beta, H0=H0, Omega_m0=Omega_m0, Omega_Lambda0=Omega_Lambda0,Mstar=Mstar)*(-Fisher_psipsi[0,1]+cofactor_psipsi[indices['z'],indices['Ag']]*cofactor_psipsi[indices['M'],indices['Ag']]*(Ag-Gdot)**2))))\n",
    "\n",
    "    return_val = Constant*Expterm*pvacterm\n",
    "\n",
    "    if return_val < 1e-50: #underflow handling\n",
    "        return 1e-50\n",
    "    else:\n",
    "        return return_val\n",
    "\n",
    "def Isource_loc(M, z, vec_l, K, alpha, beta, f, mu_l, sigma_l, Fisher, H0,Omega_m0,Omega_Lambda0, Mstar, indices = {'M':0, 'z': 1, 'Al':2, 'nl':3}):\n",
    "    \"\"\"\n",
    "    Source Integral approximation in the local effect hypothesis.\n",
    "    M, z (np.float64) are the inferred vacuum parameters of the source. K, alpha, beta are the corresponding hyperparameters.\n",
    "    vec_l (list/numpy 1d.array) = [Al, nl] is the list of inferred local effect parameters of the source.\n",
    "    f (np.float64), mu_l = [mu_Al, mu_nl], sigma_l = [sigma_Al, sigma_nl] are the hyperparameters of the local effect.\n",
    "    Fisher = Fisher_psipsi with coordinates [lnM, z, Al, nl] 4x4\n",
    "    \"\"\"\n",
    "\n",
    "    sigma_l = np.array(sigma_l)\n",
    "    mu_l = np.array(mu_l)\n",
    "    vec_l = np.array(vec_l)\n",
    "    \n",
    "    Al, nl = vec_l\n",
    "    \n",
    "    #getting the Fisher for vac+local effect parameters\n",
    "    dpsi = len(list(indices.keys()))\n",
    "    \n",
    "    indices_vac = {}\n",
    "    for key in list(indices.keys()):\n",
    "        if key in ['M','z']:\n",
    "            indices_vac[key] = indices[key]\n",
    "\n",
    "    dv = len(list(indices_vac.keys()))\n",
    "\n",
    "    indices_loc = {}\n",
    "    for key in list(indices.keys()):\n",
    "        if key in ['Al','nl']:\n",
    "            indices_loc[key] = indices[key]\n",
    "            \n",
    "    dl = len(list(indices_loc.keys()))\n",
    "    \n",
    "    Fisher_psipsi_inds = np.ix_(list(indices.values()),list(indices.values()))\n",
    "    Fisher_psipsi = Fisher[Fisher_psipsi_inds] #Full Fisher in vac+local\n",
    "\n",
    "    Fisher_vac_inds = np.ix_(list(indices_vac.values()),list(indices_vac.values()))\n",
    "    Fisher_vac = Fisher[Fisher_vac_inds] #vacuum elements only\n",
    "\n",
    "    Fisher_loc_inds = np.ix_(list(indices_loc.values()),list(indices_loc.values()))\n",
    "    Fisher_loc = Fisher[Fisher_loc_inds]  #local effect elements only\n",
    "\n",
    "    ### calculating the standardization factor in product of multivariate Gaussians\n",
    "    #Fisher_tilde = Fisher_psipsi + [[0,0],[0,Fisher_l]]\n",
    "    \n",
    "    Fisher_l = np.diag(1/sigma_l**2)\n",
    "\n",
    "    Fisher_tilde_additional = np.zeros_like(Fisher_psipsi)\n",
    "    Fisher_tilde_additional[dl:,dl:] = Fisher_l\n",
    "\n",
    "    Fisher_tilde = Fisher_psipsi + Fisher_tilde_additional #Fisher_tilde\n",
    "\n",
    "    #psitilde\n",
    "    psi_tilde_additional = np.zeros(dpsi)\n",
    "    psi_tilde_additional[dl:] = Fisher_l@mu_l\n",
    "\n",
    "    psi_vec = np.array([np.log(M),z,Al,nl])\n",
    "                \n",
    "    psi_tilde = np.linalg.inv(Fisher_tilde)@(Fisher_psipsi@psi_vec  + psi_tilde_additional) #psi_tilde\n",
    "    \n",
    "    lnM_tilde, z_tilde = psi_tilde[:dv] #v_tilde for I2 evaluation\n",
    "    \n",
    "    #standardization factor\n",
    "    S = np.linalg.det(Fisher_loc+Fisher_l)**(1/2)/((2*np.pi)**(dpsi/2))*np.exp(-1/2*(vec_l - mu_l)@(Fisher_loc+Fisher_l)@(vec_l - mu_l))\n",
    "    #S = 1\n",
    "\n",
    "    ### Calculating the source terms\n",
    "    I1 = (1-f)*((np.linalg.det(Fisher_psipsi)/np.linalg.det(Fisher_vac))**(1/2))/((2*np.pi)**((dpsi-dv)/2))*Isource_vac(M=M, z=z, K=K, alpha=alpha, beta=beta, Fisher=Fisher,H0=H0, Omega_m0=Omega_m0, Omega_Lambda0=Omega_Lambda0,Mstar=Mstar)\n",
    "\n",
    "    #print(np.linalg.det(Fisher_psipsi)/np.linalg.det(Fisher_vac))\n",
    "    \n",
    "    I2 = S*f*Isource_vac(M=np.exp(lnM_tilde), z=z_tilde, K=K, alpha=alpha, beta=beta, Fisher=Fisher, H0=H0, Omega_m0=Omega_m0, Omega_Lambda0=Omega_Lambda0,Mstar=Mstar)\n",
    "    \n",
    "    return I1 + I2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6c7dcc-074a-4e79-9ed3-e10615938921",
   "metadata": {},
   "source": [
    "### Main class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3aabed9-c7d8-48dc-b06c-e4ffc25ade3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hierarchical:\n",
    "\n",
    "    \"\"\"\n",
    "        This class generates a population of extreme-mass-ratio inspirals (EMRIs) \n",
    "        for a fiducial set of hyperparameters on local and global perturbative effects on top of vacuum evolution \n",
    "        and calculates the approximate Bayes factor (Savage-Dickey ratio) comparing \n",
    "        three hypothesis: vacuum, vac+local effect only, vac+global effect only.\n",
    "\n",
    "    Args:\n",
    "        Npop (int): Number of EMRIs in the true population.\n",
    "        SNR_thresh (float): Signal-to-noise ratio threshold to claim 'detected' EMRI set.\n",
    "        sef_kwargs (dict): keyword arguments to provide to the StableEMRIFishers class. Must include:\n",
    "                           'EMRI_waveform_gen', 'param_names'. All others optional.\n",
    "\n",
    "        filename (string): folder name where the data is being stored. No default because impractical to not save results.\n",
    "        filename_Fisher (string): a sub-folder for storing Fisher files (book-keeping). If None, Fishers directly stored in filename. Default is None. \n",
    "\n",
    "        true_hyper (dict): true values of all hyperparameters. Default are fiducial values consistent with a population of vacuum EMRIs.\n",
    "        cosmo_params (dict): true values of 'Omega_m0' (matter density), 'Omega_Lambda0' (DE density), and 'H0' (Hubble constant in m/s/Gpc).\n",
    "\n",
    "        source_bounds (dict): prior range on source parameters in all three hypotheses. Keys are param names and values are lists of lower and upper bounds. \n",
    "                              Must be provided for all parameters. We assume flat priors in this range.\n",
    "        hyper_bounds (dict): prior range on population (hyper)params in all three hypotheses. Keys are param names and values are lists of lower and upper bounds. \n",
    "                             Must be provided for all hyperparams. We assume flat priors in this range.\n",
    "\n",
    "        Tplunge_range (Union(list,NoneType)): lower and upper bounds on the time-to-plunge on EMRIs in the population. This will be used to initialize p0's for all EMRIs.\n",
    "                              Default is None corresponding to Tplunge_range = [0.5,T_LISA + 1.0].\n",
    "        \n",
    "        T_LISA (float): time (in years) of LISA observation window. Default is 1.0.\n",
    "        dt (float): LISA sampling frequency. Default is 1.0.\n",
    "        Mstar (float) Constant in prior_vac. Default is 3e6. We choose it here following https://arxiv.org/pdf/1703.09722. Future implementations can vary this also.\n",
    "\n",
    "        M_random (int): Number of random samples for Savage-Dickey ratio calculation. Default is int(1e4).\n",
    "        Fisher_validation_kwargs (dict): Keyword arguments for FisherValidation class for Kulback-Leibler divergence calculation. \n",
    "                                         If not empty, must provide keys: ('KL_threshold', 'filename_Fisher_loc', 'filename_Fisher_glob', 'validate').\n",
    "        make_nice_plots (bool): Make and save visualizations: scatterplots of source param distributions, inferred bias corner plots, source integrals as a function\n",
    "                                function of hyperparameters, etc.\n",
    "        plots_filename (string): custom filename for the plots file if make_nice_plots is True. If not provided, but make_nice_plots is True, plots are saved under the default name \"fancy_plots\". \n",
    "        \n",
    "        random_seed (int or None): seed for random processes throughout the code. If NoneType, no seed is implemented. Default is 42.\n",
    "    \n",
    "    Returns:\n",
    "        Bvac_loc (float): Savage-Dickey ratio preferring the vacuum \n",
    "        Bvac_glob (float): Savage-Dickey ratio preferring the vacuum over the global hypothesis.\n",
    "        Bloc_glob (float): Savage-Dickey ratio preferring the local over the global hypothesis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, Npop, SNR_thresh, sef_kwargs,\n",
    "                       filename,filename_Fishers=None,\n",
    "                       true_hyper={'K':5e-3,'alpha':0.0,'beta':0.0,\n",
    "                                   'f':0.0,'mu_Al':1e-5,'mu_nl':8.0,'sigma_Al':1e-6,'sigma_nl':0.8,\n",
    "                                   'Gdot':0.0},\n",
    "                       cosmo_params={'Omega_m0':0.30,'Omega_Lambda0':0.70,'H0':70e3}, \n",
    "                       source_bounds={'M':[1e4,1e7],'z':[0.01,10.0],'Al':[0.0,1e-4],'nl':[0.0,10.0],'Ag':[0.0,1e-8]},\n",
    "                       hyper_bounds={'K':[1e-3,1e-2],'alpha':[-0.5,0.5],'beta':[-0.5,0.5],\n",
    "                                     'f':[0.0,1.0],'mu_Al':[1e-5,1e-5],'mu_nl':[8.0,8.0],'sigma_Al':[1e-6,1e-6],'sigma_nl':[0.8,0.8],\n",
    "                                     'Gdot':[0.0,1e-8]},\n",
    "                       Tplunge_range = None,\n",
    "                       T_LISA = 1.0, dt = 10.0, Mstar = 3e6,\n",
    "                       M_random = int(1e4),\n",
    "                       Fisher_validation_kwargs = {},\n",
    "                       out_of_bound_nature = 'edge',\n",
    "                       make_nice_plots=False,\n",
    "                       plots_filename='fancy_plots',\n",
    "                       random_seed=42):\n",
    "\n",
    "        if isinstance(Npop, int):\n",
    "            self.Npop = Npop\n",
    "        else:\n",
    "            raise ValueError(\"Npop must be an integer > 0.\")\n",
    "\n",
    "        self.SNR_thresh = SNR_thresh\n",
    "\n",
    "        self.filename = filename\n",
    "        self.filename_Fishers = os.path.join(self.filename,filename_Fishers)\n",
    "        self.sef_kwargs = sef_kwargs\n",
    "        self.sef_kwargs['filename'] = self.filename_Fishers\n",
    "\n",
    "        #true cosmology\n",
    "        self.cosmo_params = cosmo_params\n",
    "        \n",
    "        self.Omega_m0 = cosmo_params['Omega_m0']\n",
    "        self.Omega_Lambda0 = cosmo_params['Omega_Lambda0']\n",
    "        self.H0 = cosmo_params['H0']\n",
    "\n",
    "        #true population hyperparams.\n",
    "        # K, alpha, beta are vacuum population hyperparameters\n",
    "        # f, mu_Al, mu_nl, sigma_Al, sigma_nl are local-effect population hyperparameters\n",
    "        # Gdot is the global-effect population hyperparameter.\n",
    "        self.true_hyper = true_hyper\n",
    "        \n",
    "        self.K_truth = true_hyper['K']\n",
    "        self.alpha_truth = true_hyper['alpha']\n",
    "        self.beta_truth = true_hyper['beta']\n",
    "        self.Mstar_truth = Mstar\n",
    "        self.lambda_truth_vac = [self.K_truth,self.alpha_truth,self.beta_truth]\n",
    "        \n",
    "        self.f_truth = true_hyper['f']\n",
    "        self.mu_Al_truth = true_hyper['mu_Al']\n",
    "        self.mu_nl_truth = true_hyper['mu_nl']\n",
    "        self.sigma_Al_truth = true_hyper['sigma_Al']\n",
    "        self.sigma_nl_truth = true_hyper['sigma_nl']\n",
    "        self.lambda_truth_loc = [self.f_truth,[self.mu_Al_truth,self.mu_nl_truth],[self.sigma_Al_truth,self.sigma_nl_truth]]\n",
    "        \n",
    "        self.Gdot_truth = true_hyper['Gdot']\n",
    "        self.lambda_truth_glob = [self.Gdot_truth]\n",
    "\n",
    "        #prior ranges on source parameters\n",
    "        self.source_bounds = source_bounds\n",
    "        \n",
    "        self.M_range = source_bounds['M']\n",
    "        self.z_range = source_bounds['z']\n",
    "        self.Al_range = source_bounds['Al']\n",
    "        self.nl_range = source_bounds['nl']\n",
    "        self.Ag_range = source_bounds['Ag']\n",
    "\n",
    "        #prior ranges on population (hyper)params\n",
    "        self.hyper_bounds = hyper_bounds\n",
    "        self.K_range = hyper_bounds['K']\n",
    "        self.alpha_range = hyper_bounds['alpha']\n",
    "        self.beta_range = hyper_bounds['beta']\n",
    "        self.f_range = hyper_bounds['f']\n",
    "        self.mu_Al_range = hyper_bounds['mu_Al']\n",
    "        self.mu_nl_range = hyper_bounds['mu_nl']\n",
    "        self.sigma_Al_range = hyper_bounds['sigma_Al']\n",
    "        self.sigma_nl_range = hyper_bounds['sigma_nl']\n",
    "        self.Gdot_range = hyper_bounds['Gdot']\n",
    "\n",
    "        if Tplunge_range == None:\n",
    "            self.Tplunge_range = [0.5,T_LISA + 1.0]\n",
    "        else:\n",
    "            self.Tplunge_range = Tplunge_range\n",
    "\n",
    "        self.T_LISA = T_LISA\n",
    "        self.dt = dt\n",
    "\n",
    "        self.M_random = M_random\n",
    "\n",
    "        self.Fisher_validation_kwargs = Fisher_validation_kwargs\n",
    "\n",
    "        if out_of_bound_nature in ['edge', 'remove']:\n",
    "            self.out_of_bound_nature = out_of_bound_nature\n",
    "        else:\n",
    "            warnings.warn(\"valid option for out_of_bound_nature: ['edge','remove']. Assuming default ('edge').\")\n",
    "            self.out_of_bound_nature = 'edge'\n",
    "            \n",
    "        self.make_nice_plots = make_nice_plots\n",
    "\n",
    "        if self.make_nice_plots:\n",
    "            self.plots_folder = os.path.join(self.filename, plots_filename)\n",
    "                \n",
    "            os.makedirs(self.plots_folder, exist_ok=True)\n",
    "\n",
    "        self.seed = random_seed\n",
    "\n",
    "    def __call__(self):\n",
    "\n",
    "        ###########################################################################\n",
    "        #generate a population according to prior distribution of model parameters\n",
    "        #and the true values of population parameters\n",
    "        ###########################################################################\n",
    "\n",
    "        grid_size = int(1e4) #harcoded because does not matter as long as reasonably large.\n",
    "\n",
    "        #generating vacuum parameter samples\n",
    "        self.M_truth_samples, self.z_truth_samples = M_z_samples(N=self.Npop,\n",
    "                                                                 M_range=self.M_range,z_range=self.z_range,\n",
    "                                                                 lambda_v=self.lambda_truth_vac,grid_size=grid_size,\n",
    "                                                                 H0=self.H0,Omega_m0=self.Omega_m0,Omega_Lambda0=self.Omega_Lambda0,Mstar=self.Mstar_truth,\n",
    "                                                                 seed=self.seed)\n",
    "\n",
    "        if self.make_nice_plots:\n",
    "            plt.figure(figsize=(7,5))\n",
    "            plt.scatter(np.log10(self.M_truth_samples),self.z_truth_samples,color='grey',alpha=0.5)\n",
    "            plt.xlabel(r\"$\\log_{10}$(MBH masses M)\",fontsize=16)\n",
    "            plt.ylabel(\"redshifts z\", fontsize=16)\n",
    "            plt.title(\"True population\",fontsize=16)\n",
    "            plt.savefig(f'{self.plots_folder}/M_z_truth.png',dpi=300,bbox_inches='tight')\n",
    "            plt.close()\n",
    "        \n",
    "        #generating local effect parameters samples\n",
    "        self.Al_truth_samples, self.nl_truth_samples = A_n_samples(N=self.Npop,lambda_l=self.lambda_truth_loc,seed=self.seed)\n",
    "        \n",
    "        if self.make_nice_plots:\n",
    "            plt.figure(figsize=(7,5))\n",
    "            plt.scatter(self.Al_truth_samples,self.nl_truth_samples,color='grey',alpha=0.5)\n",
    "            plt.xlabel(r\"local-effect amp $A_l$\",fontsize=16)\n",
    "            plt.ylabel(r\"local-effect slope $n_l$\", fontsize=16)\n",
    "            plt.title(\"True population\",fontsize=16)\n",
    "            plt.savefig(f'{self.plots_folder}/Al_nl_truth.png',dpi=300,bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "        \n",
    "        #generating global effect parameter samples \n",
    "        self.Ag_truth_samples = Ag_samples(N=self.Npop,lambda_g=self.lambda_truth_glob)\n",
    "\n",
    "        if self.make_nice_plots:\n",
    "            plt.figure(figsize=(7,5))\n",
    "            plt.plot(self.Ag_truth_samples,color='grey')\n",
    "            plt.ylabel(r\"global-effect amp $A_g$\", fontsize=16)\n",
    "            plt.xlabel(\"Source index\",fontsize=16)\n",
    "            plt.title(\"True population\",fontsize=16)\n",
    "            plt.savefig(f'{self.plots_folder}/Ag_truth.png',dpi=300,bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "        #generating all other model parameter samples\n",
    "        (self.mu_truth_samples,\n",
    "         self.a_truth_samples,\n",
    "         self.qS_truth_samples,\n",
    "         self.qK_truth_samples,\n",
    "         self.phiS_truth_samples,\n",
    "         self.phiK_truth_samples,\n",
    "         self.Phi0_truth_samples,\n",
    "         self.T_truth_samples) = other_param_samples(N=self.Npop,M_samples=self.M_truth_samples,Tplunge_range=self.Tplunge_range,seed=self.seed)\n",
    "        \n",
    "        try:\n",
    "            self.p0_truth_samples = np.loadtxt(f\"{self.filename}/p0samps.txt\")\n",
    "            print(\"p0 samples found\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"calculating p0 samples\")\n",
    "            self.p0_truth_samples = p0_samples_func(N=self.Npop,Msamps=self.M_truth_samples,\n",
    "                                                    musamps=self.mu_truth_samples,\n",
    "                                                    asamps=self.a_truth_samples,\n",
    "                                                    Alsamps=self.Al_truth_samples,\n",
    "                                                    nlsamps=self.nl_truth_samples,\n",
    "                                                    Agsamps=self.Ag_truth_samples,\n",
    "                                                    Tsamps=self.T_truth_samples,\n",
    "                                                    seed=self.seed,\n",
    "                                                    filename=self.filename)\n",
    "\n",
    "        if self.make_nice_plots:\n",
    "            plt.figure(figsize=(7,5))\n",
    "            plt.scatter(np.log10(self.mu_truth_samples/self.M_truth_samples),self.p0_truth_samples,color='grey',alpha=0.5)\n",
    "            plt.xlabel(r\"$\\log_{10}$(Mass ratio)\",fontsize=16)\n",
    "            plt.ylabel(r\"$p_0$\", fontsize=16)\n",
    "            plt.title(\"True population\",fontsize=16)\n",
    "            plt.savefig(f'{self.plots_folder}/q_p0_truth.png',dpi=300,bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "        #####################################################################\n",
    "        #extracting the detected population using SNR threshold calculation\n",
    "        #####################################################################\n",
    "        self.calculate_detected()\n",
    "\n",
    "        #print(self.detected_EMRIs)\n",
    "\n",
    "        ####################################################################\n",
    "        #transforming the Fishers from [M,dL,Al,nl,Ag] to [logM,z,Al,nl,Ag]\n",
    "        ####################################################################\n",
    "\n",
    "        Fisher_index = []\n",
    "        varied_params = []\n",
    "        for i in range(len(self.detected_EMRIs)):\n",
    "            varied_params.append(np.array(np.array(self.detected_EMRIs[i]['transformed_params'])))\n",
    "            Fisher_index.append(int(self.detected_EMRIs[i]['index']))\n",
    "            \n",
    "        varied_params = np.array(varied_params)\n",
    "        Fisher_index = np.array(Fisher_index)\n",
    "\n",
    "        for index, i in zip(Fisher_index,range(len(Fisher_index))):\n",
    "        \n",
    "            with h5py.File(f\"{self.filename_Fishers}/Fisher_{index}.h5\", \"r\") as f:\n",
    "                Gamma_i = f[\"Fisher\"][:]\n",
    "                    \n",
    "            dist_i = self.detected_EMRIs[i]['true_params'][6] #true_params[6] = dist\n",
    "            M_i = self.detected_EMRIs[i]['true_params'][0] #true_params[0] = M\n",
    "            \n",
    "            J = Jacobian(M_i, dist_i,self.H0,self.Omega_m0,self.Omega_Lambda0)\n",
    "            \n",
    "            Fisher_transformed = J.T@Gamma_i@J\n",
    "\n",
    "            if (np.linalg.eigvals(Fisher_transformed) < 0.0).any():\n",
    "                warnings.warn(\"positive-definiteness check failed for index: \", index)\n",
    "                warnings.warn(f\"removing source {index}...\")\n",
    "                self.detected_EMRIs = np.delete(self.detected_EMRIs, i)\n",
    "                \n",
    "            else:    \n",
    "                print(\"positive-definiteness check passed for index: \", index, \"saving Fisher...\")\n",
    "                with h5py.File(f\"{self.filename_Fishers}/Fisher_{index}.h5\", \"a\") as f:\n",
    "                    if not \"Fisher_transformed\" in f:\n",
    "                        f.create_dataset(\"Fisher_transformed\", data = Fisher_transformed)\n",
    "                \n",
    "        np.save(f\"{self.filename}/detected_EMRIs\",self.detected_EMRIs) #save updated list with check on positive-definiteness of Fisher_transformed\n",
    "\n",
    "        ##################################################################\n",
    "        #calculating the biased inferrence params in all three hypotheses\n",
    "        ##################################################################\n",
    "    \n",
    "        self.inferred_params(hypothesis='vacuum')         \n",
    "        self.inferred_params(hypothesis='local')         \n",
    "        self.inferred_params(hypothesis='global')\n",
    "\n",
    "        if self.make_nice_plots:\n",
    "            self.corner_plot_biases()\n",
    "\n",
    "        #######################################################\n",
    "        #perform Fisher validation if KL_threshold is provided\n",
    "        #######################################################\n",
    "\n",
    "        if len(self.Fisher_validation_kwargs.keys()) > 0:\n",
    "            print('Validating Fishers using KL-divergence...')\n",
    "            \n",
    "            self.KL_threshold = self.Fisher_validation_kwargs['KL_threshold']\n",
    "            _, filename_Fishers = os.path.split(self.filename_Fishers)\n",
    "            self.filename_Fishers_loc = self.Fisher_validation_kwargs['filename_Fishers_loc']\n",
    "            self.filename_Fishers_glob = self.Fisher_validation_kwargs['filename_Fishers_glob']\n",
    "            validate = self.Fisher_validation_kwargs['validate']\n",
    "\n",
    "            fishervalidate = FisherValidation(self.sef_kwargs,\n",
    "                     self.filename, filename_Fishers, self.filename_Fishers_loc, self.filename_Fishers_glob,\n",
    "                     self.true_hyper, self.cosmo_params, self.source_bounds, self.hyper_bounds,\n",
    "                     self.T_LISA, self.dt,\n",
    "                     validate)\n",
    "    \n",
    "            fishervalidate()\n",
    "            \n",
    "            if self.make_nice_plots:\n",
    "                fishervalidate.KL_divergence_plot(self.plots_folder)\n",
    "\n",
    "        #############################################################\n",
    "        #calculating the Savage-Dickey ratios in different hypotheses        \n",
    "        #############################################################\n",
    "\n",
    "        #savage-dickey preferring the vacuum hypothesis over local\n",
    "        Bvac_loc = self.savage_dickey_vacloc()\n",
    "        #print(\"Preference for vacuum over local: \", Bvac_loc)\n",
    "\n",
    "        Bvac_glob = self.savage_dickey_vacglob()\n",
    "        #print(\"Preference for vacuum over global: \", Bvac_glob)\n",
    "\n",
    "        Bglob_loc = Bvac_loc/Bvac_glob\n",
    "        #print(\"Preference for global over local: \", Bglob_loc)\n",
    "\n",
    "        np.savetxt(f\"{self.filename}/SD_ratios.txt\",np.array([Bvac_loc,Bvac_glob,Bglob_loc]))\n",
    "\n",
    "        return Bvac_loc, Bvac_glob, Bglob_loc\n",
    "\n",
    "    def calculate_detected(self):\n",
    "        \"\"\" calculate the SNRs of the sources in the population. For sources with SNR > thresh,\n",
    "        calculate and save the FIMs and parameter values. \"\"\"\n",
    "\n",
    "        try:\n",
    "            self.detected_EMRIs = np.load(f'{self.filename}/detected_EMRIs.npy', allow_pickle=True)\n",
    "            all_SNRs = np.loadtxt(f'{self.filename}/all_SNRs.txt')\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(\"Calculating FIMs for the detectable EMRI population.\")\n",
    "            \n",
    "            self.detected_EMRIs = []\n",
    "            all_SNRs = []\n",
    "                    \n",
    "            for i in tqdm(range(self.Npop)):\n",
    "                M = self.M_truth_samples[i]\n",
    "                mu = self.mu_truth_samples[i]\n",
    "                a = self.a_truth_samples[i]\n",
    "                e0 = 0.0\n",
    "                Y0 = 1.0\n",
    "                dL = getdistGpc(self.z_truth_samples[i],self.H0,self.Omega_m0,self.Omega_Lambda0) #Gpc\n",
    "                \n",
    "                qS = self.qS_truth_samples[i]\n",
    "                phiS = self.phiS_truth_samples[i]\n",
    "                qK = self.qK_truth_samples[i]\n",
    "                phiK = self.phiK_truth_samples[i]\n",
    "                Phi_phi0 = self.Phi0_truth_samples[i]\n",
    "                Phi_theta0 = 0.0\n",
    "                Phi_r0 = 0.0\n",
    "                T = self.T_LISA #all sources plunge at or after T_LISA, so the observation window is T_LISA at max.\n",
    "                dt = self.dt\n",
    "    \n",
    "                Al = self.Al_truth_samples[i]\n",
    "                nl = self.nl_truth_samples[i]\n",
    "    \n",
    "                Ag = self.Ag_truth_samples[i]\n",
    "                ng = 4.0\n",
    "    \n",
    "                p0 = self.p0_truth_samples[i]\n",
    "    \n",
    "                self.sef_kwargs['suffix'] = i\n",
    "    \n",
    "                param_list = [M,mu,a,p0,e0,Y0,\n",
    "                              dL,qS,phiS,qK,phiK,Phi_phi0,Phi_theta0,Phi_r0,\n",
    "                              ] #SEF param args (vacuum-GR EMRI)\n",
    "\n",
    "                add_param_args = {\"Al\":Al, \"nl\":nl, \"Ag\":Ag, \"ng\":ng} #dict of additional parameters\n",
    "    \n",
    "                transformed_params = [np.log(M),self.z_truth_samples[i],Al,nl,Ag]\n",
    "                \n",
    "                emri_kwargs = {'T': T, 'dt': dt}\n",
    "    \n",
    "                #print(param_list, self.T_truth_samples[i])\n",
    "                \n",
    "                sef = StableEMRIFisher(*param_list, add_param_args=add_param_args, **emri_kwargs, **self.sef_kwargs)\n",
    "                all_SNRs.append(sef.SNRcalc_SEF())\n",
    "    \n",
    "                if all_SNRs[i] >= self.SNR_thresh:\n",
    "                    self.detected_EMRIs.append({'index': i,'true_params': np.array(param_list),'SNR':all_SNRs[i], \n",
    "                                                'lambda_v':self.lambda_truth_vac, 'lambda_l':self.lambda_truth_loc, 'lambda_g':self.lambda_truth_glob,\n",
    "                                               'transformed_params':np.array(transformed_params)})\n",
    "                    try:\n",
    "                        with h5py.File(f\"{self.filename_Fishers}/Fisher_{i}.h5\", \"r\") as f:\n",
    "                            Gamma_i = f[\"Fisher\"][:]\n",
    "                    except FileNotFoundError:\n",
    "                        sef() #calculate and save the FIM for the detected EMRI\n",
    "    \n",
    "            all_SNRs = np.array(all_SNRs)\n",
    "            self.detected_EMRIs = np.array(self.detected_EMRIs)\n",
    "            np.save(f\"{self.filename}/detected_EMRIs\",self.detected_EMRIs)\n",
    "            np.savetxt(f\"{self.filename}/all_SNRs.txt\",np.array(all_SNRs))\n",
    "    \n",
    "        print(f\"#detected EMRIs: {len(self.detected_EMRIs)}\")\n",
    "\n",
    "        if self.make_nice_plots:\n",
    "            counts, bins, patches = plt.hist(all_SNRs, bins=50)\n",
    "            for patch, bin_left in zip(patches, bins[:-1]):\n",
    "                if bin_left >= self.SNR_thresh:\n",
    "                    patch.set_facecolor('red')\n",
    "                else:\n",
    "                    patch.set_facecolor('grey')\n",
    "\n",
    "            plt.axvline(self.SNR_thresh,color='k',linestyle='--',label='SNR threshold')\n",
    "            plt.legend()\n",
    "            plt.xlabel(\"SNRs\",fontsize=16)\n",
    "            plt.yscale(\"log\")\n",
    "            plt.savefig(f\"{self.plots_folder}/SNR_dist.png\",dpi=300,bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "    def inferred_params(self,hypothesis='vacuum'):\n",
    "        \"\"\" calculate and save the inferred biased params in the given hypothesis.\n",
    "        choose between 'vacuum', 'local', or 'global' \n",
    "        \"\"\"\n",
    "        \n",
    "        for i in range(len(self.detected_EMRIs)):\n",
    "        \n",
    "            # d: number of measured source params\n",
    "            # Nphi: number of unmeasured params\n",
    "            # Npsi: number of measured params\n",
    "        \n",
    "            index = int(self.detected_EMRIs[i][\"index\"])\n",
    "            with h5py.File(f\"{self.filename_Fishers}/Fisher_{index}.h5\", \"r\") as f:\n",
    "                Gamma_i = f[\"Fisher_transformed\"][:] #Fisher in transformed coords [lnM,z,Al,nl,Ag]\n",
    "    \n",
    "            if hypothesis == 'vacuum':\n",
    "                #vacuum hypothesis\n",
    "                indices_psi = [0,1]  #indices of measured params (lnM, z)\n",
    "                indices_phi = [2,3,4] #indices of unmeasured params (Al, nl, Ag)\n",
    "                \n",
    "                i_psipsi = np.ix_(indices_psi,indices_psi)\n",
    "                i_psiphi = np.ix_(indices_psi,indices_phi)\n",
    "                i_phiphi = np.ix_(indices_phi,indices_phi) \n",
    "                \n",
    "                Gamma_i_psipsi_inv = np.linalg.inv(Gamma_i[i_psipsi]) # Npsi x Npsi array\n",
    "                Gamma_i_psiphi = Gamma_i[i_psiphi] # Npsi x Nphi array\n",
    "            \n",
    "                multiplicative_factor = Gamma_i_psipsi_inv@Gamma_i_psiphi # Npsi x Nphi array\n",
    "                \n",
    "                psi_i = np.array(self.detected_EMRIs[i][\"transformed_params\"])[indices_psi] #Npsi 1D array\n",
    "                phi_i = np.array(self.detected_EMRIs[i][\"transformed_params\"])[indices_phi] #Nphi 1D array\n",
    "    \n",
    "                psi_i_inferred = bias(psi_i, phi_i, multiplicative_factor)\n",
    "                psi_i_inferred = np.concatenate((psi_i_inferred,[0.0,0.0,0.0])) #size = Npsi + Nphi\n",
    "    \n",
    "                self.detected_EMRIs[i][\"vacuum_params\"] = np.array(psi_i_inferred) #save [lnM_bias,z_bias]\n",
    "    \n",
    "            if hypothesis == 'local':\n",
    "                #local hypothesis\n",
    "                indices_psi = [0,1,2,3]  #indices of measured params (lnM,z,Al,nl)\n",
    "                indices_phi = [4] #indices of unmeasured params (Ag)\n",
    "                \n",
    "                i_psipsi = np.ix_(indices_psi,indices_psi)\n",
    "                i_psiphi = np.ix_(indices_psi,indices_phi)\n",
    "                i_phiphi = np.ix_(indices_phi,indices_phi) \n",
    "                \n",
    "                Gamma_i_psipsi_inv = np.linalg.inv(Gamma_i[i_psipsi]) # Npsi x Npsi array\n",
    "                Gamma_i_psiphi = Gamma_i[i_psiphi] # Npsi x Nphi array\n",
    "            \n",
    "                multiplicative_factor = Gamma_i_psipsi_inv@Gamma_i_psiphi # Npsi x Nphi array\n",
    "                \n",
    "                psi_i = np.array(self.detected_EMRIs[i][\"transformed_params\"])[indices_psi] #Npsi 1D array\n",
    "                phi_i = np.array(self.detected_EMRIs[i][\"transformed_params\"])[indices_phi] #Nphi 1D array\n",
    "    \n",
    "                psi_i_inferred = bias(psi_i, phi_i, multiplicative_factor)\n",
    "                \"\"\"\n",
    "                if psi_i_inferred[2] < 1e-14:\n",
    "                    psi_i_inferred[2] = 1e-14 #Al cannot be negative.\n",
    "                    psi_i_inferred[3] = 1e-14\n",
    "                if psi_i_inferred[3] < 1e-14:\n",
    "                    psi_i_inferred[3] = 1e-14 #nl cannot be negative.\n",
    "                    psi_i_inferred[2] = 1e-14\n",
    "                \"\"\"\n",
    "                psi_i_inferred = np.concatenate((psi_i_inferred,[0.0])) #size = Npsi + Nphi\n",
    "    \n",
    "                self.detected_EMRIs[i][\"local_params\"] = np.array(psi_i_inferred) #save [lnM_bias,z_bias,Al_bias, nl_bias]\n",
    "    \n",
    "            if hypothesis == 'global':\n",
    "                #global hypothesis\n",
    "                indices_psi = [0,1,4]  #indices of measured params (lnM,z,Ag)\n",
    "                indices_phi = [2,3] #indices of unmeasured params (Al,nl)\n",
    "                \n",
    "                i_psipsi = np.ix_(indices_psi,indices_psi)\n",
    "                i_psiphi = np.ix_(indices_psi,indices_phi)\n",
    "                i_phiphi = np.ix_(indices_phi,indices_phi) \n",
    "    \n",
    "                Gamma_i_psipsi_inv = np.linalg.inv(Gamma_i[i_psipsi]) # Npsi x Npsi array\n",
    "                Gamma_i_psiphi = Gamma_i[i_psiphi] # Npsi x Nphi array\n",
    "    \n",
    "                multiplicative_factor = Gamma_i_psipsi_inv@Gamma_i_psiphi # Npsi x Nphi array\n",
    "    \n",
    "                psi_i = np.array(self.detected_EMRIs[i][\"transformed_params\"])[indices_psi] #Npsi 1D array\n",
    "                phi_i = np.array(self.detected_EMRIs[i][\"transformed_params\"])[indices_phi] #Nphi 1D array\n",
    "    \n",
    "                psi_i_inferred = bias(psi_i, phi_i, multiplicative_factor)\n",
    "                \"\"\"\n",
    "                if psi_i_inferred[-1] < 1e-14:\n",
    "                    psi_i_inferred[-1] = 1e-14 #global effect cannot be negative.\n",
    "                \"\"\"\n",
    "                psi_i_inferred = np.concatenate((np.concatenate((psi_i_inferred[:2],[0.0,0.0])),[psi_i_inferred[-1]]))\n",
    "                \n",
    "                self.detected_EMRIs[i][\"global_params\"] = np.array(psi_i_inferred) #save [lnM_bias,z_bias,Ag_bias]\n",
    "\n",
    "        self.Nobs = len(self.detected_EMRIs) #number of detected EMRIs.\n",
    "        np.save(f'{self.filename}/detected_EMRIs',self.detected_EMRIs)\n",
    "\n",
    "    def source_integral_vac(self,K,alpha,beta):\n",
    "        \n",
    "        \"\"\"Calculate the source integral in the vacuum hypothesis.\n",
    "        bounds_vac is a dict of bounds on M and z. Bounds can be given for any subset of the parameters.\"\"\"\n",
    "                \n",
    "        #calculate source integral\n",
    "        Ivac_all = []\n",
    "\n",
    "        Nobs = self.Nobs\n",
    "        count = 0.0 #number of out of bound EMRIs\n",
    "        \n",
    "        bounds_vac = {'logM':np.log(self.source_bounds['M']),'z':self.source_bounds['z']}\n",
    "\n",
    "        for i in range(len(self.detected_EMRIs)):\n",
    "            \n",
    "            out_of_bounds = False\n",
    "            index = int(self.detected_EMRIs[i][\"index\"])\n",
    "            with h5py.File(f\"{self.filename_Fishers}/Fisher_{index}.h5\", \"r\") as f:\n",
    "                Fisher = f[\"Fisher_transformed\"][:] #Fisher in transformed coords [lnM,z,Al,nl,Ag]\n",
    "            \n",
    "            vacparams = self.detected_EMRIs[i][\"vacuum_params\"] # logMvac, zvac, Alvac, nlvac, Agvac\n",
    "        \n",
    "            for param,j in zip(bounds_vac.keys(),range(len(bounds_vac.keys()))):\n",
    "                if check_prior(vacparams[j],bounds_vac[param]) == 1: #if the source parameters hits the upper limit\n",
    "                    out_of_bounds = True\n",
    "                    warnings.warn(f\"source {index} is out of prior bounds on {param} (upper bound hit). \\n\\\n",
    "                            Parameter value: {vacparams[j]}. Bound: {bounds_vac[param]}.\")\n",
    "                    varparams[j] = bounds_vac[param][1] #varparam takes the upper limit value\n",
    "                elif check_prior(vacparams[j],bounds_vac[param]) == -1: #if the source parameter hits the lower limit\n",
    "                    out_of_bounds = True\n",
    "                    warnings.warn(f\"source {index} is out of prior bounds on {param} (lower bound hit). \\n\\\n",
    "                            Parameter value: {vacparams[j]}. Bound: {bounds_vac[param]}.\")\n",
    "                    vacparams[j] = bounds_vac[param][0] #vacparam takes the lower limit value\n",
    "\n",
    "            if out_of_bounds:\n",
    "                count+=1\n",
    "\n",
    "            Ivac_i = Isource_vac(M=np.exp(vacparams[0]),z=vacparams[1], \n",
    "                                K=K, alpha=alpha, beta=beta, #variable hyperparameters\n",
    "                                Fisher=Fisher,H0=self.H0,Omega_m0=self.Omega_m0,Omega_Lambda0=self.Omega_Lambda0,Mstar=self.Mstar_truth)\n",
    "\n",
    "            if out_of_bounds and self.out_of_bound_nature == 'remove':\n",
    "                Ivac_all.append(1.0)\n",
    "                Nobs -= 1\n",
    "\n",
    "            else:\n",
    "                Ivac_all.append(Ivac_i)\n",
    "    \n",
    "        warnings.warn(f\"EMRIs out-of-bounds: {int(count)} out of total {int(len(Fishers_all))}\")\n",
    "    \n",
    "        return factorial(Nobs-1)*np.prod(np.array(Ivac_all))\n",
    "\n",
    "    def source_integral_loc(self,K,alpha,beta,f,mu_Al,mu_nl,sigma_Al,sigma_nl,Fishers_all,indices_all,locparams_all):\n",
    "        \n",
    "        \"\"\"Calculate the source integral in the local hypothesis.\n",
    "        bounds_loc is a dict of bounds on M, z, Al, nl. Bounds can be given for any subset of the parameters.\"\"\"\n",
    "        \n",
    "        Nobs = self.Nobs\n",
    "        count = 0.0 #number of out of bound EMRIs\n",
    "        \n",
    "        #calculate source integral\n",
    "        Iloc_all = []\n",
    "\n",
    "        bounds_loc = {'logM':np.log(self.source_bounds['M']),'z':self.source_bounds['z'],\n",
    "                      'Al':self.source_bounds['Al'],'nl':self.source_bounds['nl']} #prior range\n",
    "    \n",
    "        for i, index in zip(range(len(Fishers_all)),indices_all):\n",
    "            out_of_bounds = False\n",
    "            Fisher = Fishers_all[i] #Fisher in transformed coords [lnM,z,Al,nl,Ag]\n",
    "            locparams = locparams_all[i]\n",
    "            \n",
    "            for param,j in zip(bounds_loc.keys(),range(len(bounds_loc.keys()))):\n",
    "                if check_prior(locparams[j],bounds_loc[param]) == 1: #if the source parameters hits the upper limit\n",
    "                    out_of_bounds = True\n",
    "                    warnings.warn(f\"source {index} is out of prior bounds on {param} (upper bound hit). \\n\\\n",
    "                            Parameter value: {locparams[j]}. Bound: {bounds_loc[param]}.\")\n",
    "                    locparams[j] = bounds_loc[param][1] #locparam takes the upper limit value\n",
    "                elif check_prior(locparams[j],bounds_loc[param]) == -1: #if the source parameter hits the lower limit\n",
    "                    out_of_bounds = True\n",
    "                    warnings.warn(f\"source {index} is out of prior bounds on {param} (lower bound hit). \\n\\\n",
    "                            Parameter value: {locparams[j]}. Bound: {bounds_loc[param]}.\")\n",
    "                    locparams[j] = bounds_loc[param][0] #locparam takes the lower limit value\n",
    "\n",
    "            if out_of_bounds:\n",
    "                count+=1\n",
    "    \n",
    "            Iloc_i = Isource_loc(M=np.exp(locparams[0]),z=locparams[1], vec_l=[locparams[2],locparams[3]], \n",
    "                                K=K, alpha=alpha, beta=beta, \n",
    "                                f=f, mu_l=[mu_Al,mu_nl], sigma_l=[sigma_Al,sigma_nl], \n",
    "                                Fisher=Fisher,H0=self.H0,Omega_m0=self.Omega_m0,Omega_Lambda0=self.Omega_Lambda0,\n",
    "                                Mstar=self.Mstar_truth)\n",
    "    \n",
    "            if out_of_bounds and self.out_of_bound_nature == 'remove':\n",
    "                Iloc_all.append(1.0)\n",
    "                Nobs -= 1\n",
    "                \n",
    "            elif np.isnan(Iloc_i):\n",
    "                Iloc_all.append(1.0)\n",
    "                Nobs -= 1\n",
    "                \n",
    "            else:\n",
    "                Iloc_all.append(Iloc_i)\n",
    "\n",
    "        lnposterior = np.sum(np.log(np.array(Iloc_all))) #avoid overflow by calculating log posterior\n",
    "        if count > 0.0:\n",
    "            warnings.warn(f\"EMRIs out-of-bounds: {int(count)} out of total {int(len(Fishers_all))}\")\n",
    "        \n",
    "        return lnposterior\n",
    "\n",
    "    def source_integral_glob(self,K,alpha,beta,Gdot,Fishers_all,indices_all,globparams_all):\n",
    "        \n",
    "        \"\"\"Calculate the source integral in the global hypothesis.\n",
    "        bounds_loc is a dict of bounds on M, z, Al, nl. Bounds can be given for any subset of the parameters.\"\"\"\n",
    "            \n",
    "        Nobs = self.Nobs\n",
    "        count = 0.0 #number of out of bound EMRIs\n",
    "        \n",
    "        #calculate source integral\n",
    "        Iglob_all = []\n",
    "\n",
    "        bounds_glob = {'logM':np.log(self.source_bounds['M']),'z':self.source_bounds['z'],\n",
    "                      'Ag':self.source_bounds['Ag']} #prior range\n",
    "    \n",
    "        for i, index in zip(range(len(Fishers_all)),indices_all):\n",
    "            out_of_bounds = False\n",
    "            Fisher = Fishers_all[i] #Fisher in transformed coords [lnM,z,Al,nl,Ag]\n",
    "    \n",
    "            globparams = globparams_all[i] # logMglob, zglob, Alglob, nlglob, Agglob\n",
    "            \n",
    "            for param,j in zip(bounds_glob.keys(),range(len(bounds_glob.keys()))):\n",
    "                if check_prior(globparams[j],bounds_glob[param]) == 1: #if the source parameters hits the upper limit\n",
    "                    out_of_bounds = True\n",
    "                    warnings.warn(f\"source {index} is out of prior bounds on {param} (upper bound hit). \\n\\\n",
    "                            Parameter value: {globparams[j]}. Bound: {bounds_glob[param]}.\")\n",
    "                    globparams[j] = bounds_glob[param][1] #varparam takes the upper limit value\n",
    "                elif check_prior(globparams[j],bounds_glob[param]) == -1: #if the source parameter hits the lower limit\n",
    "                    out_of_bounds = True\n",
    "                    warnings.warn(f\"source {index} is out of prior bounds on {param} (lower bound hit). \\n\\\n",
    "                            Parameter value: {globparams[j]}. Bound: {bounds_glob[param]}.\")\n",
    "                    globparams[j] = bounds_glob[param][0] #vacparam takes the lower limit value\n",
    "\n",
    "            if out_of_bounds:\n",
    "                count+=1\n",
    "    \n",
    "            Iglob_i = Isource_glob(M=np.exp(globparams[0]),z=globparams[1],Ag=globparams[-1],\n",
    "                                  K=K, alpha=alpha, beta=beta, \n",
    "                                  Gdot=Gdot,Mstar=self.Mstar_truth,\n",
    "                                  Fisher=Fisher,H0=self.H0,Omega_m0=self.Omega_m0,Omega_Lambda0=self.Omega_Lambda0)\n",
    "            \n",
    "            if out_of_bounds and self.out_of_bound_nature == 'remove':\n",
    "                Iglob_all.append(1.0)\n",
    "                Nobs -= 1\n",
    "\n",
    "            elif np.isnan(Iglob_i):\n",
    "                Iglob_all.append(1.0)\n",
    "                Nobs -= 1\n",
    "                \n",
    "            else:\n",
    "                Iglob_all.append(Iglob_i)\n",
    "\n",
    "        lnposterior = np.sum(np.log(np.array(Iglob_all))) #avoid overflow by calculating log posterior\n",
    "        if count > 0.0:\n",
    "            warnings.warn(f\"EMRIs out-of-bounds: {int(count)} out of total {int(len(Fishers_all))}\")\n",
    "\n",
    "        return lnposterior\n",
    "\n",
    "    def savage_dickey_vacloc(self):\n",
    "        #no seed ideally required for this calculation\n",
    "        t = 1e6 * time.time() # current time in microseconds\n",
    "        np.random.seed(int(t) % 2**32)\n",
    "\n",
    "        samples = np.random.uniform(\n",
    "                                    low=[self.K_range[0], self.alpha_range[0], self.beta_range[0], self.f_range[0], \n",
    "                                         self.mu_Al_range[0], self.mu_nl_range[0], self.sigma_Al_range[0], self.sigma_nl_range[0]],\n",
    "                                    high=[self.K_range[1], self.alpha_range[1], self.beta_range[1], self.f_range[1], \n",
    "                                          self.mu_Al_range[1], self.mu_nl_range[1], self.sigma_Al_range[1], self.sigma_nl_range[1]],\n",
    "                                    size=(self.M_random, 8)\n",
    "                                    )\n",
    "        \n",
    "        K_samples, alpha_samples, beta_samples, f_samples, mu_Al_samples, mu_nl_samples, sigma_Al_samples, sigma_nl_samples = samples.T\n",
    "\n",
    "        #make sure f_samples have at least 10% draws at the null value for SD calculation\n",
    "        f_samples = f_samples[:int(0.9*self.M_random)]\n",
    "        f_samples = np.concatenate((f_samples,np.zeros(self.M_random-len(f_samples))))\n",
    "\n",
    "        Fishers_all = []\n",
    "        indices_all = []\n",
    "        locparams_all = []      \n",
    "        for i in range(len(self.detected_EMRIs)):\n",
    "            index = int(self.detected_EMRIs[i][\"index\"])\n",
    "            indices_all.append(index)\n",
    "            \n",
    "            with h5py.File(f\"{self.filename_Fishers}/Fisher_{index}.h5\", \"r\") as f:\n",
    "                Fish_trans = f[\"Fisher_transformed\"][:]\n",
    "                \n",
    "            Fishers_all.append(Fish_trans)\n",
    "            \n",
    "            locparams_all.append(self.detected_EMRIs[i][\"local_params\"])\n",
    "\n",
    "        indices_all = np.array(indices_all)\n",
    "        Fishers_all = np.array(Fishers_all)\n",
    "        locparams_all = np.array(locparams_all)\n",
    "        \n",
    "        #only choose Fishers which satisfy the KL-divergence threshold, if available.\n",
    "        if len(self.Fisher_validation_kwargs.keys()) > 0:\n",
    "            if self.f_truth > 0:\n",
    "                Fishers_loc_KL = np.loadtxt(f'{self.filename}/Fishers_loc_KL.txt')\n",
    "                Fishers_all_KL = []\n",
    "                indices_all_KL = []\n",
    "                locparams_all_KL = []\n",
    "                j = 0\n",
    "                for i in range(len(self.detected_EMRIs)):\n",
    "                    Al = self.detected_EMRIs[i]['local_params'][2]\n",
    "                    nl = self.detected_EMRIs[i]['local_params'][3]\n",
    "                    Ag = self.detected_EMRIs[i]['local_params'][4] #will be zero in local hypothesis\n",
    "                    ng = 4.0\n",
    "            \n",
    "                    if Fishers_loc_KL[j] < self.KL_threshold: #KL-divergence of jth source should be less than the threshold.\n",
    "                        Fishers_all_KL.append(Fishers_all[j])\n",
    "                        indices_all_KL.append(indices_all[j])\n",
    "                        locparams_all_KL.append(locparams_all[j])\n",
    "\n",
    "                    j += 1 #hacky afterthought to cycle through Fishers_loc_KL\n",
    "\n",
    "                Fishers_all = np.array(Fishers_all_KL) #update Fishers_all\n",
    "                indices_all = np.array(indices_all_KL) #update indices_all\n",
    "\n",
    "                if len(Fishers_all) != len(self.detected_EMRIs):\n",
    "                    warnings.warn(f\"After KL-divergence validation, only {len(Fishers_all)} sources remain.\")\n",
    "        \n",
    "        lnprodIsource = []\n",
    "        removed_indices = []\n",
    "    \n",
    "        for j in tqdm(range(self.M_random)):\n",
    "            lnprodIsource_j = self.source_integral_loc(K=K_samples[j],alpha=alpha_samples[j],beta=beta_samples[j],\n",
    "                                                        f=f_samples[j],mu_Al=mu_Al_samples[j],mu_nl=mu_nl_samples[j],\n",
    "                                                        sigma_Al=sigma_Al_samples[j],sigma_nl=sigma_nl_samples[j],\n",
    "                                                        Fishers_all=Fishers_all, indices_all=indices_all,locparams_all=locparams_all)\n",
    "            \n",
    "            lnprodIsource.append(lnprodIsource_j)\n",
    "    \n",
    "        lnprodIsource = np.array(lnprodIsource) - np.max(lnprodIsource)\n",
    "        prodIsource = np.exp(lnprodIsource)\n",
    "\n",
    "        for i in range(len(prodIsource)):\n",
    "            if prodIsource[i] < 1e-300: #control underflow\n",
    "                prodIsource[i] = 1e-300\n",
    "        \n",
    "        prodIsource = prodIsource/np.sum(prodIsource)\n",
    "        \n",
    "        #f=0 mask\n",
    "        num_bins = 40\n",
    "        mask = np.abs(f_samples - 0.0) < (max(f_samples)-min(f_samples))/num_bins\n",
    "        \n",
    "        while sum(mask) < 10: #make sure at least ten sample point in the null hypothesis.\n",
    "            warnings.warn(\"No samples consistent with the null hypothesis. Reducing bin size. The Bayes factor may be incorrect. Increase M_samples!\")\n",
    "            num_bins -= 5\n",
    "            mask = np.abs(f_samples - 0.0) < (max(f_samples)-min(f_samples))/num_bins\n",
    "            \n",
    "        prior_f0 = sum(mask)/len(prodIsource) #prior number of points within the bin for f = 0 \n",
    "        posterior_f0 = np.sum(prodIsource[mask])\n",
    "    \n",
    "        print(\"prior_f0: \", prior_f0)\n",
    "        print(\"posterior_f0: \", posterior_f0)\n",
    "\n",
    "        if self.make_nice_plots:\n",
    "            plt.figure(figsize=(7,5))\n",
    "            plt.scatter(f_samples, prodIsource,color='grey',alpha=0.5,label='all posterior samples')\n",
    "            plt.scatter(f_samples[mask],prodIsource[mask],color='red',alpha=0.5,label='posterior consistent with null')\n",
    "            plt.axvline(self.f_truth,color='k',linestyle='--',label='truth')\n",
    "            plt.xlabel(\"fraction of local-effect EMRIs (f)\", fontsize=16)\n",
    "            plt.ylabel(\"posterior pdf p(f|data)\",fontsize=16)\n",
    "            plt.yscale('log')\n",
    "            plt.legend()\n",
    "            plt.savefig(f\"{self.plots_folder}/posterior_vac_loc_f.png\",dpi=300,bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure(figsize=(7,5))\n",
    "            plt.scatter(mu_Al_samples, prodIsource,color='grey',alpha=0.5,label='all posterior samples')\n",
    "            plt.scatter(mu_Al_samples[mask],prodIsource[mask],color='red',alpha=0.5,label='posterior consistent with null')\n",
    "            plt.axvline(self.mu_Al_truth,color='k',linestyle='--',label='truth')\n",
    "            plt.xlabel(r\"mean disk-effect amplitude of local-effect EMRIs ($\\mu_{Al}$)\", fontsize=16)\n",
    "            plt.ylabel(r\"posterior pdf p($\\mu_{Al}$|data)\",fontsize=16)\n",
    "            plt.yscale('log')\n",
    "            plt.legend()\n",
    "            plt.savefig(f\"{self.plots_folder}/posterior_vac_loc_muAl.png\",dpi=300,bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure(figsize=(7,5))\n",
    "            plt.scatter(mu_nl_samples, prodIsource,color='grey',alpha=0.5,label='all posterior samples')\n",
    "            plt.scatter(mu_nl_samples[mask],prodIsource[mask],color='red',alpha=0.5,label='posterior consistent with null')\n",
    "            plt.axvline(self.mu_nl_truth,color='k',linestyle='--',label='truth')\n",
    "            plt.xlabel(r\"mean disk-effect slope of local-effect EMRIs ($\\mu_{nl}$)\", fontsize=16)\n",
    "            plt.ylabel(r\"posterior pdf p($\\mu_{nl}$|data)\",fontsize=16)\n",
    "            plt.yscale('log')\n",
    "            plt.legend()\n",
    "            plt.savefig(f\"{self.plots_folder}/posterior_vac_loc_munl.png\",dpi=300,bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure(figsize=(7,5))\n",
    "            plt.scatter(sigma_Al_samples, prodIsource,color='grey',alpha=0.5,label='all posterior samples')\n",
    "            plt.scatter(sigma_Al_samples[mask],prodIsource[mask],color='red',alpha=0.5,label='posterior consistent with null')\n",
    "            plt.axvline(self.sigma_Al_truth,color='k',linestyle='--',label='truth')\n",
    "            plt.xlabel(r\"std of disk-effect amplitude of local-effect EMRIs ($\\sigma_{Al}$)\", fontsize=16)\n",
    "            plt.ylabel(r\"posterior pdf p($\\sigma_{Al}$|data)\",fontsize=16)\n",
    "            plt.yscale('log')\n",
    "            plt.legend()\n",
    "            plt.savefig(f\"{self.plots_folder}/posterior_vac_loc_sigmaAl.png\",dpi=300,bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure(figsize=(7,5))\n",
    "            plt.scatter(sigma_nl_samples, prodIsource,color='grey',alpha=0.5,label='all posterior samples')\n",
    "            plt.scatter(sigma_nl_samples[mask],prodIsource[mask],color='red',alpha=0.5,label='posterior consistent with null')\n",
    "            plt.axvline(self.sigma_nl_truth,color='k',linestyle='--',label='truth')\n",
    "            plt.xlabel(r\"std of disk-effect slope of local-effect EMRIs ($\\sigma_{nl}$)\", fontsize=16)\n",
    "            plt.ylabel(r\"posterior pdf p($\\sigma_{nl}$|data)\",fontsize=16)\n",
    "            plt.yscale('log')\n",
    "            plt.legend()\n",
    "            plt.savefig(f\"{self.plots_folder}/posterior_vac_loc_sigmanl.png\",dpi=300,bbox_inches='tight')\n",
    "            plt.close()\n",
    "        \n",
    "        return posterior_f0/prior_f0\n",
    "    \n",
    "    def savage_dickey_vacglob(self):\n",
    "        #no seed ideally required for this calculation\n",
    "        t = 1e6 * time.time() # current time in microseconds\n",
    "        np.random.seed(int(t) % 2**32)\n",
    "\n",
    "        samples = np.random.uniform(\n",
    "                                    low=[self.K_range[0], self.alpha_range[0], self.beta_range[0], self.Gdot_range[0]],\n",
    "                                    high=[self.K_range[1], self.alpha_range[1], self.beta_range[1], self.Gdot_range[1]],\n",
    "                                    size=(self.M_random, 4)\n",
    "                                    )\n",
    "        \n",
    "        K_samples, alpha_samples, beta_samples, Gdot_samples = samples.T\n",
    "\n",
    "        #make sure Gdot_samples have at least 10% draws at the null value for SD calculation\n",
    "        Gdot_samples = Gdot_samples[:int(0.9*self.M_random)]\n",
    "        Gdot_samples = np.concatenate((Gdot_samples,np.zeros(self.M_random-len(Gdot_samples))))\n",
    "\n",
    "        indices_all = []\n",
    "        Fishers_all = []\n",
    "        globparams_all = []\n",
    "        for i in range(len(self.detected_EMRIs)):\n",
    "            index = int(self.detected_EMRIs[i][\"index\"])\n",
    "            indices_all.append(index)\n",
    "            \n",
    "            with h5py.File(f\"{self.filename_Fishers}/Fisher_{index}.h5\", \"r\") as f:\n",
    "                Fish_trans = f[\"Fisher_transformed\"][:]\n",
    "                \n",
    "            Fishers_all.append(Fish_trans)\n",
    "            globparams_all.append(self.detected_EMRIs[i][\"global_params\"])\n",
    "\n",
    "        indices_all = np.array(indices_all)\n",
    "        Fishers_all = np.array(Fishers_all)\n",
    "        globparams_all = np.array(globparams_all)\n",
    "\n",
    "        #only choose Fishers which satisfy the KL-divergence threshold, if available.\n",
    "        if len(self.Fisher_validation_kwargs.keys()) > 0:\n",
    "            if self.Gdot_truth > 0:\n",
    "                Fishers_glob_KL = np.loadtxt(f'{self.filename}/Fishers_glob_KL.txt')\n",
    "                Fishers_all_KL = []\n",
    "                indices_all_KL = []\n",
    "                globparams_all_KL = []\n",
    "                j = 0\n",
    "                for i in range(len(self.detected_EMRIs)):\n",
    "                    Al = self.detected_EMRIs[i]['global_params'][2] #will be zero in global hypothesis\n",
    "                    nl = self.detected_EMRIs[i]['global_params'][3] #will be zero in global hypothesis\n",
    "                    Ag = self.detected_EMRIs[i]['global_params'][4] \n",
    "                    ng = 4.0\n",
    "            \n",
    "                    if Fishers_glob_KL[j] < self.KL_threshold: #KL-divergence of jth source should be less than the threshold.\n",
    "                        Fishers_all_KL.append(Fishers_all[j])\n",
    "                        indices_all_KL.append(indices_all[j])\n",
    "                        globparams_all_KL.append(globparams_all[j])\n",
    "\n",
    "                    j += 1 #hacky afterthought to cycle through Fishers_glob_KL\n",
    "\n",
    "                Fishers_all = np.array(Fishers_all_KL) #update Fishers_all\n",
    "                indices_all = np.array(indices_all_KL) #update indices_all\n",
    "\n",
    "                if len(Fishers_all) != len(self.detected_EMRIs):\n",
    "                    warnings.warn(f\"After KL-divergence validation, only {len(Fishers_all)} sources remain.\")\n",
    "    \n",
    "        lnprodIsource = []\n",
    "        #removed_indices = []\n",
    "        for j in tqdm(range(self.M_random)):\n",
    "                \n",
    "            lnprodIsource_j = self.source_integral_glob(K=K_samples[j], alpha=alpha_samples[j], beta=beta_samples[j],\n",
    "                                                  Gdot=Gdot_samples[j],Fishers_all=Fishers_all,indices_all=indices_all,globparams_all=globparams_all)\n",
    "\n",
    "            #print(K_samples[j], alpha_samples[j], beta_samples[j], Gdot_samples[j], prodIsource_j)\n",
    "    \n",
    "            lnprodIsource.append(lnprodIsource_j)\n",
    "    \n",
    "        lnprodIsource = np.array(lnprodIsource) - np.max(lnprodIsource)\n",
    "        prodIsource = np.exp(lnprodIsource)\n",
    "\n",
    "        for i in range(len(prodIsource)):\n",
    "            if prodIsource[i] < 1e-300: #control underflow\n",
    "                prodIsource[i] = 1e-300\n",
    "                \n",
    "        prodIsource = prodIsource/np.sum(prodIsource)\n",
    "            \n",
    "        #Gdot=0 mask\n",
    "        num_bins = 40\n",
    "        mask = np.abs(Gdot_samples - 0.0) < (max(Gdot_samples)-min(Gdot_samples))/num_bins\n",
    "\n",
    "        while sum(mask) < 10: #make sure at least ten sample point in the null hypothesis.\n",
    "            warnings.warn(\"No samples consistent with the null hypothesis. Reducing bin size. The Bayes factor may be incorrect. Increase M_samples!\")\n",
    "            num_bins -= 5\n",
    "            mask = np.abs(Gdot_samples - 0.0) < (max(Gdot_samples)-min(Gdot_samples))/num_bins\n",
    "        \n",
    "        prior_Gdot0 = sum(mask)/self.M_random #prior number of points within the bin for Gdot = 0 \n",
    "        posterior_Gdot0 = np.sum(prodIsource[mask])\n",
    "    \n",
    "        print(\"prior_Gdot0: \", prior_Gdot0)\n",
    "        print(\"posterior_Gdot0: \", posterior_Gdot0)\n",
    "\n",
    "        if self.make_nice_plots:\n",
    "            plt.figure(figsize=(7,5))\n",
    "            plt.scatter(Gdot_samples, prodIsource,color='grey',alpha=0.5,label='all posterior samples')\n",
    "            plt.scatter(Gdot_samples[mask],prodIsource[mask],color='red',alpha=0.5,label='posterior consistent with null')\n",
    "            plt.axvline(self.Gdot_truth,color='k',linestyle='--',label='truth')\n",
    "            plt.xlabel(\"value of global-effect (Gdot)\",fontsize=16)\n",
    "            plt.ylabel(\"posterior pdf p(Gdot|data)\",fontsize=16)\n",
    "            plt.yscale('log')\n",
    "            plt.legend()\n",
    "            plt.savefig(f\"{self.plots_folder}/posterior_vac_glob.png\",dpi=300,bbox_inches='tight')\n",
    "            plt.close()\n",
    "        \n",
    "        return posterior_Gdot0/prior_Gdot0\n",
    "\n",
    "    def corner_plot_biases(self):\n",
    "        Fisher_index = []\n",
    "        varied_params = []\n",
    "        vacuum_params = []\n",
    "        local_params = []\n",
    "        global_params = []\n",
    "        SNRs = []\n",
    "        \n",
    "        for i in range(len(self.detected_EMRIs)):\n",
    "            varied_params.append(np.array(np.array(self.detected_EMRIs[i]['transformed_params'])))\n",
    "            vacuum_params.append(self.detected_EMRIs[i]['vacuum_params'])\n",
    "            local_params.append(self.detected_EMRIs[i]['local_params'])\n",
    "            global_params.append(self.detected_EMRIs[i]['global_params'])\n",
    "            Fisher_index.append(int(self.detected_EMRIs[i]['index']))\n",
    "            SNRs.append(self.detected_EMRIs[i]['SNR'])\n",
    "            \n",
    "        varied_params = np.array(varied_params)\n",
    "        vacuum_params = np.array(vacuum_params)\n",
    "        local_params = np.array(local_params)\n",
    "        global_params = np.array(global_params)\n",
    "        Fisher_index = np.array(Fisher_index)\n",
    "        SNRs = np.array(SNRs)\n",
    "        \n",
    "        params = ['$\\\\log{M}$','$z$','$A_l$','$n_l$','$A_g$']\n",
    "        param_lims = [np.log(self.M_range),self.z_range,self.Al_range,self.nl_range,self.Ag_range]\n",
    "        fig, axs = plt.subplots(len(params),len(params),figsize=(40,40))\n",
    "\n",
    "        plt.subplots_adjust(hspace=0, wspace=0)\n",
    "        \n",
    "        for i in range(len(params)):\n",
    "            for j in range(len(params)):\n",
    "                if j < i:\n",
    "                    axs[i,j].scatter(varied_params[:,j],varied_params[:,i],s=SNRs,label='true',alpha=0.5)\n",
    "                    axs[i,j].scatter(vacuum_params[:,j],vacuum_params[:,i],s=SNRs,label='vac',alpha=0.5)\n",
    "                    axs[i,j].scatter(local_params[:,j],local_params[:,i],s=SNRs,label='loc',alpha=0.5)\n",
    "                    axs[i,j].scatter(global_params[:,j],global_params[:,i],s=SNRs,label='global',alpha=0.5)\n",
    "\n",
    "                    axs[i, j].grid(linestyle='--')\n",
    "                    \n",
    "                    if i == len(params)-1:\n",
    "                        axs[i,j].set_xlabel(params[j],fontsize=46)\n",
    "                    else:\n",
    "                        axs[i, j].set_xticklabels([])\n",
    "                    if j == 0:\n",
    "                        axs[i,j].set_ylabel(params[i],fontsize=46)\n",
    "                    else:\n",
    "                        axs[i, j].set_yticklabels([])\n",
    "                    \n",
    "                    axs[i,j].set_xlim(param_lims[j])\n",
    "                    axs[i,j].set_ylim(param_lims[i])\n",
    "                    \n",
    "                else:\n",
    "                    axs[i,j].remove()\n",
    "        \n",
    "        handles, labels = axs[1, 0].get_legend_handles_labels()\n",
    "        fig.legend(handles, labels, fontsize=60, loc='upper right', bbox_to_anchor=(0.7, 0.7))  # Place legend outside\n",
    "\n",
    "        plt.savefig(f\"{self.plots_folder}/inferred_vs_truth.png\",dpi=300,bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d679d4a-53b9-4662-9974-33a876d417f4",
   "metadata": {},
   "source": [
    "#### waveform model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b6a725d-b466-4109-8aeb-9d1ea5409aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_LISA = 1. #LISA observation duration\n",
    "dt = 10.0 #sampling rate\n",
    "\n",
    "max_step_days = 20.0 #maximum step size for inspiral calculation. Smaller number ensures a more accurate trajectory but requires higher computation time.\n",
    "\n",
    "insp_kwargs = { \"err\": 1e-11, #Default: 1e-11 in FEW 2\n",
    "                \"max_step_size\": max_step_days*24*60*60, #in seconds\n",
    "                \"buffer_length\":int(1e6), \n",
    "               }\n",
    "\n",
    "sum_kwargs = {\n",
    "    \"pad_output\": True, # True if expecting waveforms smaller than LISA observation window.\n",
    "}\n",
    "\n",
    "Waveform_model = GenerateEMRIWaveform(\n",
    "            JointKerrWaveform,\n",
    "            inspiral_kwargs=insp_kwargs,\n",
    "            sum_kwargs=sum_kwargs,\n",
    "            use_gpu=use_gpu,\n",
    "            return_list=False,\n",
    "            frame=\"detector\"\n",
    "            )\n",
    "\n",
    "#orbit_file_esa = \"/home/shubham/FEW_KerrEcc/Github_Repos/lisa-on-gpu/orbit_files/esa-trailing-orbits.h5\"\n",
    "# orbit_file_esa = \"/data/lsperi/lisa-on-gpu/orbit_files/equalarmlength-trailing-fit.h5\"\n",
    "#orbit_kwargs_esa = dict(orbit_file=orbit_file_esa)\n",
    "\n",
    "tdi_gen =\"1st generation\"# \"2nd generation\"#\n",
    "\n",
    "order = 20  # interpolation order (should not change the result too much)\n",
    "tdi_kwargs_esa = dict(\n",
    "    orbits=ESAOrbits(use_gpu=use_gpu), order=order, tdi=tdi_gen, tdi_chan=\"AE\",\n",
    ")  # could do \"AET\"\n",
    "\n",
    "index_lambda = 8\n",
    "index_beta = 7\n",
    "\n",
    "# with longer signals we care less about this\n",
    "t0 = 10000.0  # throw away on both ends when our orbital information is weird\n",
    "\n",
    "EMRI_TDI = ResponseWrapper(\n",
    "                        Waveform_model,\n",
    "                        T_LISA,\n",
    "                        t0=t0,\n",
    "                        dt=dt,\n",
    "                        index_lambda=index_lambda,\n",
    "                        index_beta=index_beta,\n",
    "                        flip_hx=True,  # set to True if waveform is h+ - ihx (FEW is)\n",
    "                        use_gpu=use_gpu,\n",
    "                        is_ecliptic_latitude=False,  # False if using polar angle (theta)\n",
    "                        remove_garbage=\"zero\",  # removes the beginning of the signal that has bad information\n",
    "                        **tdi_kwargs_esa,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0367031a-da14-45e6-beac-dd30e90765cf",
   "metadata": {},
   "source": [
    "#### Setup of the fiducial EMRI population and detection criteriae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "148b7671-5abb-4002-89e0-9e2cddd4b8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cosmological parameters\n",
    "cosmo_params={'Omega_m0':0.30,'Omega_Lambda0':0.70,'H0':70e3}\n",
    "\n",
    "#Mstar normalization term for the EMRI MBH mass distribution\n",
    "Mstar = 3e6\n",
    "\n",
    "#True size of the population\n",
    "Npop = int(1e2)\n",
    "\n",
    "#detection SNR threshold\n",
    "SNR_thresh = 20.0\n",
    "\n",
    "#true values of population hyperparameters.\n",
    "true_hyper={'K':5e-3,'alpha':0.2,'beta':0.2, #vacuum hyperparameters\n",
    "            'f':0.5,'mu_Al':1e-5,'mu_nl':8.0,'sigma_Al':1e-6,'sigma_nl':1.0, #local effect hyper\n",
    "            'Gdot':1e-9 #global effect hyper\n",
    "           }\n",
    "\n",
    "#prior bounds on source parameters\n",
    "source_bounds={'M':[1e5,1e7],'z':[0.01,1.0], #vacuum parameters\n",
    "               'Al':[0.0,1e-4],'nl':[0.0,20.0], #local effect parameters\n",
    "               'Ag':[0.0,1e-8] #global effect parameters\n",
    "              }\n",
    "\n",
    "#prior bounds on population hyperparameters\n",
    "hyper_bounds={'K':[1e-3,1e-2],'alpha':[-0.5,0.5],'beta':[-0.5,0.5], #vacuum hyperparameters\n",
    "             'f':[0.0,1.0],'mu_Al':[true_hyper['mu_Al']*0.9,true_hyper['mu_Al']*1.1],'mu_nl':[true_hyper['mu_nl']*0.9,true_hyper['mu_nl']*1.1],\n",
    "              'sigma_Al':[true_hyper['sigma_Al']*1e-1,true_hyper['sigma_Al']*1e2],\n",
    "              'sigma_nl':[true_hyper['sigma_nl']*1e-1,true_hyper['sigma_nl']*1e2],#local effect hyper\n",
    "             'Gdot':source_bounds['Ag'] #global effect hyper\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee04e886-58c5-4ac6-ba2e-ca0140cb7e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_Fishers_loc = 'Fishers_loc' #subfolder with inferred FIMs in local hypothesis\n",
    "filename_Fishers_glob = 'Fishers_glob' #subfolder with inferred FIMs in global hypothesis\n",
    "\n",
    "Fisher_validation_kwargs = {'filename_Fishers_loc':filename_Fishers_loc,\n",
    "                            'filename_Fishers_glob':filename_Fishers_glob,\n",
    "                            'validate':False,'KL_threshold':10.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0ad817e-a1df-4508-b0f0-8b0c232c0b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p0 samples found\n",
      "#detected EMRIs: 12\n",
      "positive-definiteness check passed for index:  4 saving Fisher...\n",
      "positive-definiteness check passed for index:  19 saving Fisher...\n",
      "positive-definiteness check passed for index:  26 saving Fisher...\n",
      "positive-definiteness check passed for index:  29 saving Fisher...\n",
      "positive-definiteness check passed for index:  40 saving Fisher...\n",
      "positive-definiteness check passed for index:  42 saving Fisher...\n",
      "positive-definiteness check passed for index:  56 saving Fisher...\n",
      "positive-definiteness check passed for index:  57 saving Fisher...\n",
      "positive-definiteness check passed for index:  61 saving Fisher...\n",
      "positive-definiteness check passed for index:  72 saving Fisher...\n",
      "positive-definiteness check passed for index:  76 saving Fisher...\n",
      "positive-definiteness check passed for index:  78 saving Fisher...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/2000 [00:00<?, ?it/s]/tmp/ipykernel_6346/119164910.py:602: UserWarning: source 4 is out of prior bounds on nl (lower bound hit). \n",
      "                            Parameter value: -2.8904289825599525. Bound: [0.0, 20.0].\n",
      "  warnings.warn(f\"source {index} is out of prior bounds on {param} (lower bound hit). \\n\\\n",
      "/tmp/ipykernel_6346/119164910.py:602: UserWarning: source 26 is out of prior bounds on Al (lower bound hit). \n",
      "                            Parameter value: -5.684224152922859e-05. Bound: [0.0, 0.0001].\n",
      "  warnings.warn(f\"source {index} is out of prior bounds on {param} (lower bound hit). \\n\\\n",
      "/tmp/ipykernel_6346/119164910.py:602: UserWarning: source 26 is out of prior bounds on nl (lower bound hit). \n",
      "                            Parameter value: -15.04595725655596. Bound: [0.0, 20.0].\n",
      "  warnings.warn(f\"source {index} is out of prior bounds on {param} (lower bound hit). \\n\\\n",
      "/tmp/ipykernel_6346/119164910.py:602: UserWarning: source 29 is out of prior bounds on Al (lower bound hit). \n",
      "                            Parameter value: -0.0001818003060367418. Bound: [0.0, 0.0001].\n",
      "  warnings.warn(f\"source {index} is out of prior bounds on {param} (lower bound hit). \\n\\\n",
      "/tmp/ipykernel_6346/119164910.py:602: UserWarning: source 29 is out of prior bounds on nl (lower bound hit). \n",
      "                            Parameter value: -41.89757861259644. Bound: [0.0, 20.0].\n",
      "  warnings.warn(f\"source {index} is out of prior bounds on {param} (lower bound hit). \\n\\\n",
      "/tmp/ipykernel_6346/119164910.py:602: UserWarning: source 40 is out of prior bounds on Al (lower bound hit). \n",
      "                            Parameter value: -2.8824674505438326e-05. Bound: [0.0, 0.0001].\n",
      "  warnings.warn(f\"source {index} is out of prior bounds on {param} (lower bound hit). \\n\\\n",
      "/tmp/ipykernel_6346/119164910.py:602: UserWarning: source 40 is out of prior bounds on nl (lower bound hit). \n",
      "                            Parameter value: -13.191862867337514. Bound: [0.0, 20.0].\n",
      "  warnings.warn(f\"source {index} is out of prior bounds on {param} (lower bound hit). \\n\\\n",
      "/tmp/ipykernel_6346/119164910.py:602: UserWarning: source 42 is out of prior bounds on Al (lower bound hit). \n",
      "                            Parameter value: -0.00028961839043591857. Bound: [0.0, 0.0001].\n",
      "  warnings.warn(f\"source {index} is out of prior bounds on {param} (lower bound hit). \\n\\\n",
      "/tmp/ipykernel_6346/119164910.py:602: UserWarning: source 42 is out of prior bounds on nl (lower bound hit). \n",
      "                            Parameter value: -48.79919758289319. Bound: [0.0, 20.0].\n",
      "  warnings.warn(f\"source {index} is out of prior bounds on {param} (lower bound hit). \\n\\\n",
      "/tmp/ipykernel_6346/119164910.py:628: UserWarning: EMRIs out-of-bounds: 5 out of total 12\n",
      "  warnings.warn(f\"EMRIs out-of-bounds: {int(count)} out of total {int(len(Fishers_all))}\")\n",
      "  5%|██                                     | 107/2000 [00:00<00:11, 168.89it/s]/tmp/ipykernel_6346/1333347936.py:3: RuntimeWarning: invalid value encountered in scalar power\n",
      "  return K*(M/Mstar)**alpha*(1+z)**beta*4*np.pi*dc(z,H0,Omega_m0,Omega_Lambda0)**2\n",
      "/tmp/ipykernel_6346/2545482524.py:52: RuntimeWarning: invalid value encountered in scalar power\n",
      "  return C*alpha*(alpha-1)*M**(alpha-2)*(1+z)**beta*dc(z,H0,Omega_m0,Omega_Lambda0)**2\n",
      "/tmp/ipykernel_6346/2545482524.py:76: RuntimeWarning: invalid value encountered in scalar power\n",
      "  term1 = (-1 + beta) * beta * C * M ** alpha * (1 + z) ** (-2 + beta) * dc(z,H0,Omega_m0,Omega_Lambda0)** 2\n",
      "/tmp/ipykernel_6346/2545482524.py:77: RuntimeWarning: invalid value encountered in scalar power\n",
      "  term2 = 4 * beta * C * M ** alpha * (1 + z) ** (-1 + beta) * dc(z,H0,Omega_m0,Omega_Lambda0)* Ddc(z,H0,Omega_m0,Omega_Lambda0)\n",
      "/tmp/ipykernel_6346/2545482524.py:78: RuntimeWarning: invalid value encountered in scalar power\n",
      "  term3 = 2 * C * M ** alpha * (1 + z) ** beta * Ddc(z,H0,Omega_m0,Omega_Lambda0) ** 2\n",
      "/tmp/ipykernel_6346/2545482524.py:79: RuntimeWarning: invalid value encountered in scalar power\n",
      "  term4 = 2 * C * M ** alpha * (1 + z) ** beta * dc(z,H0,Omega_m0,Omega_Lambda0) * DDdc(z,H0,Omega_m0,Omega_Lambda0)\n",
      "/tmp/ipykernel_6346/2545482524.py:32: RuntimeWarning: invalid value encountered in sqrt\n",
      "  term4 = -2 * H0 ** (1/3) * Ol * np.sqrt(Om * (1 + z) ** 3)\n",
      "/tmp/ipykernel_6346/2545482524.py:33: RuntimeWarning: invalid value encountered in sqrt\n",
      "  term5 = -2 * H0 * Ol ** (1/3) * Om ** (1/3) * (1 + z) * np.sqrt(Om * (1 + z) ** 3)\n",
      "/tmp/ipykernel_6346/2545482524.py:35: RuntimeWarning: invalid value encountered in scalar power\n",
      "  numerator = (-3 * C_SI * H0 * Om ** (2/3) * (1 + z) * (Om * (1 + z) ** 3) ** (3/2) *\n",
      "/tmp/ipykernel_6346/2545482524.py:39: RuntimeWarning: invalid value encountered in sqrt\n",
      "  denom1 = Ol ** (1/3) * Om ** (1/3) * (1 + z) + H0 ** (1/3) * np.sqrt(Om * (1 + z) ** 3)\n",
      "/tmp/ipykernel_6346/2545482524.py:42: RuntimeWarning: invalid value encountered in sqrt\n",
      "  H0 ** (1/3) * Ol ** (1/3) * np.sqrt(Om * (1 + z) ** 3))\n",
      "/tmp/ipykernel_6346/2545482524.py:100: RuntimeWarning: invalid value encountered in scalar power\n",
      "  term1 = alpha * beta * C * M ** (-1 + alpha) * (1 + z) ** (-1 + beta) * dc(z,H0,Omega_m0,Omega_Lambda0) ** 2\n",
      "/tmp/ipykernel_6346/2545482524.py:101: RuntimeWarning: invalid value encountered in scalar power\n",
      "  term2 = 2 * alpha * C * M ** (-1 + alpha) * (1 + z) ** beta * dc(z,H0,Omega_m0,Omega_Lambda0) * Ddc(z,H0,Omega_m0,Omega_Lambda0)\n",
      "100%|██████████████████████████████████████| 2000/2000 [00:12<00:00, 166.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior_f0:  0.12\n",
      "posterior_f0:  0.6776454816312973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2000/2000 [00:08<00:00, 230.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior_Gdot0:  0.1205\n",
      "posterior_Gdot0:  1.208686171297374e-191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(5.6470456802608116),\n",
       " np.float64(1.0030590633173229e-190),\n",
       " np.float64(5.6298236931181984e+190))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = f'Hierarchical_Npop_{Npop}_f_{true_hyper['f']}_Gdot_{true_hyper['Gdot']}_K_{true_hyper['K']}_alpha_{true_hyper['alpha']}_beta_{true_hyper['beta']}' #folder with all the analysis data and plots\n",
    "#filename = f'Hierarchical_Npop_{Npop}_varied_f_Gdot_{true_hyper['Gdot']}_K_{true_hyper['K']}_alpha_{true_hyper['alpha']}_beta_{true_hyper['beta']}/f_{true_hyper['f']}' #folder with all the analysis data and plots\n",
    "#filename = 'test_Tplunge'\n",
    "filename_Fishers = 'Fishers' #subfolder with all the Fisher matrices\n",
    "\n",
    "#noise model setup\n",
    "channels = [A1TDISens, E1TDISens]\n",
    "noise_kwargs = [{\"sens_fn\": channel_i} for channel_i in channels]\n",
    "\n",
    "#setting up kwargs to pass to StableEMRIFishers class\n",
    "sef_kwargs = {'EMRI_waveform_gen':EMRI_TDI, #EMRI waveform model with TDI response\n",
    "              'param_names': ['M','dist','Al','nl','Ag'], #params to be varied\n",
    "              'der_order':4, #derivative order\n",
    "              'Ndelta':12, #number of stable points\n",
    "              'stats_for_nerds': False, #true if you wanna print debugging info\n",
    "              'stability_plot': False, #true if you wanna plot stability surfaces\n",
    "              'use_gpu':use_gpu,\n",
    "              'plunge_check':False, #no need to check for plunge --- away from plunge already ensured.\n",
    "              'noise_model': get_sensitivity,\n",
    "              'channels':channels,\n",
    "              'noise_kwargs':noise_kwargs,\n",
    "             }\n",
    "\n",
    "hier = Hierarchical(Npop=Npop,SNR_thresh=SNR_thresh,sef_kwargs=sef_kwargs,\n",
    "                    filename=filename,filename_Fishers=filename_Fishers,\n",
    "                    cosmo_params=cosmo_params,true_hyper=true_hyper,\n",
    "                    source_bounds=source_bounds,hyper_bounds=hyper_bounds,Mstar=Mstar,\n",
    "                    T_LISA=T_LISA,make_nice_plots=True,M_random=int(2e3),\n",
    "                    #Fisher_validation_kwargs=Fisher_validation_kwargs,\n",
    "                   out_of_bound_nature='edge')\n",
    "\n",
    "hier()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
